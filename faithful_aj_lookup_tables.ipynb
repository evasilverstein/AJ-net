{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c1023a",
   "metadata": {},
   "source": [
    "\n",
    "# Faithful Abel–Jacobi lookup tables (two-sheet, cut-aware)\n",
    "\n",
    "This notebook generates lookup tables for a genus **g** hyperelliptic curve\n",
    "\n",
    "\\[\n",
    "w^2 = \\prod_{i=1}^{2g+2}(z-a_i),\n",
    "\\qquad \\omega_k = \\frac{z^k\\,dz}{w},\\; k=0,\\dots,g-1,\n",
    "\\]\n",
    "\n",
    "and precomputes Abel–Jacobi integrals on a rectangular grid:\n",
    "\n",
    "- **Sheet 0** integrals: `I0[k, iy, ix]`\n",
    "- **Sheet 1** integrals: `I1[k, iy, ix]`\n",
    "- A constant **bridge vector** `B` such that **`I0 + I1 = B`** everywhere.\n",
    "\n",
    "Key points:\n",
    "\n",
    "- We use the **straight segment** from `base_point → z` in the base plane.\n",
    "- We detect crossings with the user-chosen **branch cuts** and **flip the sheet** each time (i.e. the integrand changes sign).\n",
    "- The straight segment ends on either sheet depending on the parity of cut crossings. Using the bridge `B`, we convert this into **tables for both sheets**.\n",
    "\n",
    "> **About `ix` and `iy`:**  \n",
    "> `ix` indexes the **x / real** grid (`grid_r[ix]`), and `iy` indexes the **y / imaginary** grid (`grid_i[iy]`).  \n",
    "> The complex coordinate is `z = grid_r[ix] + 1j * grid_i[iy]`.\n",
    "\n",
    "The tables are saved to Google Drive in the same `.pt` format as your current pipeline, but with extra keys:\n",
    "- `I0`, `I1`, `B`, and (optionally) `sheet_parity`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0becf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Setup: installs, imports, Drive mount, config\n",
    "!pip install -q torch numpy mpmath tqdm\n",
    "\n",
    "import os, time, math, json, numpy as np, torch, mpmath as mp\n",
    "from tqdm import tqdm\n",
    "from google.colab import drive\n",
    "\n",
    "# ===========================\n",
    "# 0) User config\n",
    "# ===========================\n",
    "genus = 30          # default genus (g)\n",
    "H = W = 96          # grid resolution (H rows in y, W columns in x)\n",
    "\n",
    "r_min, r_max = -6.0, 6.0\n",
    "i_min, i_max = -6.0, 6.0\n",
    "grid_r = np.linspace(r_min, r_max, W).astype(np.float64)\n",
    "grid_i = np.linspace(i_min, i_max, H).astype(np.float64)\n",
    "\n",
    "# Numerical precision (mpmath) and quadrature\n",
    "mp.mp.dps = 50      # raise if you need more precision\n",
    "N_GAUSS = 32        # Gauss–Legendre nodes per segment (32 is a decent default)\n",
    "\n",
    "# Intersection tolerance for segment–segment tests\n",
    "EPS_INTERSECT = 1e-12\n",
    "\n",
    "# Base point (choose outside the grid box)\n",
    "base_point = complex(r_min - 2.0, i_min - 2.0)\n",
    "\n",
    "# Cut generation parameters\n",
    "CUT_RADIUS = 4.0\n",
    "CUT_JITTER = 0.25\n",
    "CUT_SEED   = 123\n",
    "\n",
    "# ===========================\n",
    "# 1) Drive & save directory\n",
    "# ===========================\n",
    "DRIVE_FOLDER = f\"AJ_Tables_g{genus}_faithful\"   # change if you want to overwrite an existing folder\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "SAVE_DIR = f\"/content/drive/MyDrive/{DRIVE_FOLDER}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# File paths (ω and I saved separately, resume-safe)\n",
    "OMEGAS_PATH    = os.path.join(SAVE_DIR, f\"aj_omegas_genus{genus}.pt\")\n",
    "INTEGRALS_PATH = os.path.join(SAVE_DIR, f\"aj_integrals_genus{genus}.pt\")\n",
    "\n",
    "print(\"Will save to:\")\n",
    "print(\"  ω  :\", OMEGAS_PATH)\n",
    "print(\"  I  :\", INTEGRALS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Helper: atomic save (resume-safe)\n",
    "def atomic_torch_save(obj, path):\n",
    "    tmp = path + \".tmp\"\n",
    "    torch.save(obj, tmp)\n",
    "    os.replace(tmp, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6211c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Cuts: robust, non-overlapping construction (same style as your existing notebook)\n",
    "def make_hyperelliptic_cuts(g, radius=4.0, jitter=0.25, seed=123,\n",
    "                            r_min=-6.0, r_max=6.0, i_min=-6.0, i_max=6.0):\n",
    "    \"\"\"\n",
    "    Returns g+1 cuts [(a0,a1), ..., (a_g, a'_g)] for a hyperelliptic curve\n",
    "    with 2g+2 branch points. We place 2g+2 points on a perturbed circle and\n",
    "    pair nearest neighbors to form short segments.\n",
    "\n",
    "    This mirrors the construction in your original notebook, but parameterized.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    m = 2*g + 2\n",
    "    thetas = np.linspace(0, 2*np.pi, m, endpoint=False)\n",
    "    rng.shuffle(thetas)\n",
    "    radii = radius * (1.0 + jitter * (rng.rand(m) - 0.5))\n",
    "    pts = radii * np.exp(1j * thetas)\n",
    "\n",
    "    # Ensure within grid box (shrink if needed)\n",
    "    scale = max((pts.real.max()-pts.real.min())/(r_max-r_min+1e-6),\n",
    "                (pts.imag.max()-pts.imag.min())/(i_max-i_min+1e-6))\n",
    "    if scale > 0.85:\n",
    "        pts = pts / (scale/0.85)\n",
    "\n",
    "    remaining = list(range(m))\n",
    "    cuts = []\n",
    "    while remaining:\n",
    "        i = remaining.pop(0)\n",
    "        pi = pts[i]\n",
    "        dists = [(j, abs(pi - pts[j])) for j in remaining]\n",
    "        j = min(dists, key=lambda t: t[1])[0]\n",
    "        remaining.remove(j)\n",
    "\n",
    "        # Shorten segment slightly so endpoints are not exact branch points\n",
    "        a, b = pi, pts[j]\n",
    "        mid = 0.5*(a+b)\n",
    "        a = a + 0.05*(a - mid)\n",
    "        b = b + 0.05*(b - mid)\n",
    "        cuts.append((complex(a), complex(b)))\n",
    "\n",
    "    if len(cuts) > g+1:\n",
    "        cuts.sort(key=lambda ab: -abs(ab[0]-ab[1]))\n",
    "        cuts = cuts[:g+1]\n",
    "    assert len(cuts) == g+1\n",
    "    return cuts\n",
    "\n",
    "branch_cuts = make_hyperelliptic_cuts(\n",
    "    genus, radius=CUT_RADIUS, jitter=CUT_JITTER, seed=CUT_SEED,\n",
    "    r_min=r_min, r_max=r_max, i_min=i_min, i_max=i_max\n",
    ")\n",
    "branch_pts = [a for ab in branch_cuts for a in ab]\n",
    "\n",
    "print(f\"genus={genus} → cuts={len(branch_cuts)} ; total branch points={len(branch_pts)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd1695",
   "metadata": {},
   "source": [
    "\n",
    "## Geometry utilities: segment–segment intersection and cut crossings\n",
    "\n",
    "We parameterize the straight segment from base point \\(p\\) to target \\(q\\) as\n",
    "\\[\n",
    "p(t) = p + t(q-p),\\quad t\\in[0,1].\n",
    "\\]\n",
    "Each branch cut is a segment \\([a,b]\\). We detect all intersections \\(t\\in(0,1)\\) and sort them to split the path into subsegments.\n",
    "\n",
    "Each time we cross a cut, we **flip the sheet** (equivalently \\(w\\to -w\\) and \\(\\omega_k \\to -\\omega_k\\)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de1b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Segment intersection + cut crossing list\n",
    "def _cross2(ax, ay, bx, by):\n",
    "    return ax*by - ay*bx\n",
    "\n",
    "def segment_intersection_t(p, q, a, b, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Return the parameter t in (0,1) such that p + t(q-p) intersects the segment [a,b],\n",
    "    or None if no proper intersection.\n",
    "\n",
    "    We exclude intersections extremely close to segment endpoints using `eps`.\n",
    "    \"\"\"\n",
    "    px, py = float(p.real), float(p.imag)\n",
    "    qx, qy = float(q.real), float(q.imag)\n",
    "    ax, ay = float(a.real), float(a.imag)\n",
    "    bx, by = float(b.real), float(b.imag)\n",
    "\n",
    "    rx, ry = qx - px, qy - py\n",
    "    sx, sy = bx - ax, by - ay\n",
    "\n",
    "    denom = _cross2(rx, ry, sx, sy)\n",
    "    if abs(denom) < eps:\n",
    "        return None  # parallel or nearly parallel\n",
    "\n",
    "    apx, apy = ax - px, ay - py\n",
    "    t = _cross2(apx, apy, sx, sy) / denom\n",
    "    u = _cross2(apx, apy, rx, ry) / denom\n",
    "\n",
    "    if (eps < t < 1.0 - eps) and (eps < u < 1.0 - eps):\n",
    "        return float(t)\n",
    "    return None\n",
    "\n",
    "def cut_crossings(base, z, cuts, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Returns sorted list of (t, cut_index) for intersections of segment base->z with cuts.\n",
    "    \"\"\"\n",
    "    hits = []\n",
    "    for j, (a, b) in enumerate(cuts):\n",
    "        t = segment_intersection_t(base, z, a, b, eps=eps)\n",
    "        if t is not None:\n",
    "            hits.append((t, j))\n",
    "    hits.sort(key=lambda x: x[0])\n",
    "    return hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Quadrature nodes: Gauss–Legendre on [0,1]\n",
    "# Gauss–Legendre nodes/weights on [-1,1]\n",
    "x_gl, w_gl = np.polynomial.legendre.leggauss(N_GAUSS)\n",
    "# Map to [0,1]\n",
    "s_gl = (x_gl + 1.0) / 2.0\n",
    "w01 = w_gl / 2.0\n",
    "\n",
    "# store as Python floats (mpmath will upcast as needed)\n",
    "S_GL = [float(s) for s in s_gl]\n",
    "W_GL = [float(w) for w in w01]\n",
    "\n",
    "print(f\"Gauss–Legendre ready: N_GAUSS={N_GAUSS}, sum(weights)={sum(W_GL):.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a344a7",
   "metadata": {},
   "source": [
    "\n",
    "## Cut-aware integrator\n",
    "\n",
    "We evaluate \\(w(z)=\\sqrt{P(z)}\\) using the principal `mp.sqrt`, but **enforce continuity** along each segment by flipping the sign at quadrature nodes whenever \\(|-w - w_{\\text{prev}}| < |w - w_{\\text{prev}}|\\).\n",
    "\n",
    "When a cut is crossed, we flip the sheet: \\(w_{\\text{prev}} \\leftarrow -w_{\\text{prev}}\\).\n",
    "\n",
    "### Integrating **all** \\(k=0,\\dots,g-1\\) at once\n",
    "\n",
    "To avoid recomputing \\(P(z)\\) and \\(\\sqrt{P(z)}\\) for each \\(k\\), we compute the full vector\n",
    "\\[\n",
    "(\\int \\omega_0,\\dots,\\int \\omega_{g-1})\n",
    "\\]\n",
    "in one pass along the quadrature nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Polynomial P(z), sqrt continuation, segment integrator (all k)\n",
    "# Convert branch points to mpmath types once\n",
    "BRANCH_PTS_MP = [mp.mpc(a.real, a.imag) for a in branch_pts]\n",
    "\n",
    "def P_of_z(z_mp):\n",
    "    \"\"\"P(z)=∏(z-a_i) as an mpmath complex.\"\"\"\n",
    "    prod = mp.mpc(1)\n",
    "    for a in BRANCH_PTS_MP:\n",
    "        prod *= (z_mp - a)\n",
    "    return prod\n",
    "\n",
    "# Base-sheet choice: pick w(base_point) via principal sqrt\n",
    "BASE_MP = mp.mpc(base_point.real, base_point.imag)\n",
    "W_BASE = mp.sqrt(P_of_z(BASE_MP))\n",
    "\n",
    "def integrate_segment_allk(z0, z1, w_prev):\n",
    "    \"\"\"\n",
    "    Integrate ω_k = z^k dz / w along the straight segment z(s)=z0+s(z1-z0), s∈[0,1],\n",
    "    for all k=0..g-1 in one pass.\n",
    "    Returns (I_vec, w_end) where I_vec is list length g (mpmath complex).\n",
    "    \"\"\"\n",
    "    z0 = mp.mpc(z0.real, z0.imag)\n",
    "    z1 = mp.mpc(z1.real, z1.imag)\n",
    "    dz = z1 - z0\n",
    "\n",
    "    if abs(dz) == 0:\n",
    "        return [mp.mpc(0) for _ in range(genus)], w_prev\n",
    "\n",
    "    seg_acc = [mp.mpc(0) for _ in range(genus)]\n",
    "    w_last = w_prev\n",
    "\n",
    "    for s, wt in zip(S_GL, W_GL):\n",
    "        z = z0 + dz * s\n",
    "        w = mp.sqrt(P_of_z(z))  # principal sqrt\n",
    "\n",
    "        # enforce continuity along the segment\n",
    "        if w_last is not None and abs(w - w_last) > abs(-w - w_last):\n",
    "            w = -w\n",
    "\n",
    "        inv_w = 1 / w\n",
    "        z_pow = mp.mpc(1)\n",
    "        for k in range(genus):\n",
    "            seg_acc[k] += wt * (z_pow * inv_w)\n",
    "            z_pow *= z\n",
    "\n",
    "        w_last = w\n",
    "\n",
    "    # multiply by dz because dz/ds is constant on this segment\n",
    "    for k in range(genus):\n",
    "        seg_acc[k] *= dz\n",
    "\n",
    "    return seg_acc, w_last\n",
    "\n",
    "def integrate_straight_with_cuts_allk(z):\n",
    "    \"\"\"\n",
    "    Integrate along the straight segment base_point -> z, splitting at cut intersections.\n",
    "    Each cut crossing flips the sheet (w -> -w), implemented by flipping w_prev after each split.\n",
    "\n",
    "    Returns:\n",
    "      I_vec: list length g of mp.mpc\n",
    "      parity: (# crossings mod 2) — which sheet the straight lift ends on (0=sheet0, 1=sheet1)\n",
    "      n_cross: number of crossings\n",
    "    \"\"\"\n",
    "    hits = cut_crossings(base_point, z, branch_cuts, eps=EPS_INTERSECT)\n",
    "    n_cross = len(hits)\n",
    "    parity = n_cross % 2\n",
    "\n",
    "    # Build split points\n",
    "    pts = [base_point]\n",
    "    for t, _ in hits:\n",
    "        pts.append(base_point + t*(z - base_point))\n",
    "    pts.append(z)\n",
    "\n",
    "    I_total = [mp.mpc(0) for _ in range(genus)]\n",
    "    w_prev = W_BASE\n",
    "\n",
    "    for i in range(len(pts) - 1):\n",
    "        I_seg, w_prev = integrate_segment_allk(pts[i], pts[i+1], w_prev)\n",
    "        for k in range(genus):\n",
    "            I_total[k] += I_seg[k]\n",
    "\n",
    "        # Flip sheet after each cut crossing (i.e., between segments)\n",
    "        if i < len(pts) - 2:\n",
    "            w_prev = -w_prev\n",
    "\n",
    "    return I_total, parity, n_cross\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192cd5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Compute bridge vector B (constant): choose p on a cut and set B = 2 * ∫_{base→p} ω\n",
    "# Pick an interior point on the first cut\n",
    "a0, b0 = branch_cuts[0]\n",
    "p_bridge = 0.5*(a0 + b0)\n",
    "\n",
    "print(\"Bridge point p_bridge =\", p_bridge)\n",
    "\n",
    "I_p, parity_p, n_cross_p = integrate_straight_with_cuts_allk(p_bridge)\n",
    "B_mp = [2 * val for val in I_p]  # B is length-g vector (mpmath complex)\n",
    "\n",
    "print(f\"Computed B using cut #0 midpoint.  crossings (excluding endpoints) = {n_cross_p}, parity={parity_p}\")\n",
    "print(\"Sample entries of B:\")\n",
    "for k in range(min(3, genus)):\n",
    "    print(f\"  B[{k}] = {complex(B_mp[k])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Common metadata for files + config compatibility checks\n",
    "COMMON_META = {\n",
    "    \"genus\": genus,\n",
    "    \"branch_cuts\": branch_cuts,\n",
    "    \"branch_pts\": np.array(branch_pts, dtype=np.complex128),\n",
    "    \"grid_r\": grid_r,\n",
    "    \"grid_i\": grid_i,\n",
    "    \"meta\": {\n",
    "        \"mp_dps\": int(mp.mp.dps),\n",
    "        \"base_point\": base_point,\n",
    "        \"grid_shape\": (H, W),\n",
    "        \"ranges\": (r_min, r_max, i_min, i_max),\n",
    "        \"N_GAUSS\": int(N_GAUSS),\n",
    "        \"EPS_INTERSECT\": float(EPS_INTERSECT),\n",
    "        \"cut_seed\": int(CUT_SEED),\n",
    "        \"cut_radius\": float(CUT_RADIUS),\n",
    "        \"cut_jitter\": float(CUT_JITTER),\n",
    "    }\n",
    "}\n",
    "\n",
    "def ensure_config_compatible(payload):\n",
    "    assert int(payload[\"genus\"]) == genus\n",
    "    assert tuple(payload[\"meta\"][\"grid_shape\"]) == (H, W)\n",
    "    assert np.allclose(np.array(payload[\"grid_r\"]), grid_r)\n",
    "    assert np.allclose(np.array(payload[\"grid_i\"]), grid_i)\n",
    "    # If you want stricter checks, uncomment:\n",
    "    # assert payload[\"meta\"][\"base_point\"] == base_point\n",
    "    # assert int(payload[\"meta\"][\"N_GAUSS\"]) == int(N_GAUSS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title (Optional) Check/lock branch cuts against saved files (resume safety)\n",
    "import os, numpy as np, torch\n",
    "\n",
    "AUTO_ADOPT_SAVED_CUTS = False  # set True if you want to overwrite current cuts from saved file\n",
    "\n",
    "def pick_saved_path():\n",
    "    cand = []\n",
    "    if os.path.exists(INTEGRALS_PATH):\n",
    "        cand.append(INTEGRALS_PATH)\n",
    "    if os.path.exists(OMEGAS_PATH):\n",
    "        cand.append(OMEGAS_PATH)\n",
    "    if not cand:\n",
    "        return None\n",
    "    cand.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n",
    "    return cand[0]\n",
    "\n",
    "def np_c128_from_list(lst):\n",
    "    return np.array([complex(z) for z in lst], dtype=np.complex128)\n",
    "\n",
    "saved_path = pick_saved_path()\n",
    "if saved_path is None:\n",
    "    print(\"No saved ω/Ι file found — fresh run.\")\n",
    "else:\n",
    "    pkg = torch.load(saved_path, map_location=\"cpu\", weights_only=False)\n",
    "    saved_genus = int(pkg.get(\"genus\"))\n",
    "    saved_grid_r = np.array(pkg.get(\"grid_r\"))\n",
    "    saved_grid_i = np.array(pkg.get(\"grid_i\"))\n",
    "    saved_pts = np.array(pkg.get(\"branch_pts\", []), dtype=np.complex128)\n",
    "    saved_cuts = pkg.get(\"branch_cuts\", None)\n",
    "\n",
    "    curr_pts = np_c128_from_list(branch_pts)\n",
    "\n",
    "    print(f\"Comparing current session to: {os.path.basename(saved_path)}\")\n",
    "    ok_genus = (saved_genus == genus)\n",
    "    ok_grid  = np.allclose(saved_grid_r, grid_r) and np.allclose(saved_grid_i, grid_i)\n",
    "    ok_len   = (saved_pts.shape == curr_pts.shape)\n",
    "    ok_pts   = ok_len and np.allclose(saved_pts, curr_pts)\n",
    "\n",
    "    print(f\"  genus match : {ok_genus} (saved={saved_genus}, current={genus})\")\n",
    "    print(f\"  grid match  : {ok_grid}\")\n",
    "    if ok_len:\n",
    "        max_dev = float(np.max(np.abs(saved_pts - curr_pts))) if saved_pts.size else 0.0\n",
    "        print(f\"  branch pts  : {'MATCH' if ok_pts else 'MISMATCH'} (max |Δ| = {max_dev:.3e})\")\n",
    "    else:\n",
    "        print(f\"  branch pts  : count differs (saved {saved_pts.size}, current {curr_pts.size})\")\n",
    "\n",
    "    if ok_genus and ok_grid and ok_pts:\n",
    "        print(\"\\n✅ SAFE to resume: cuts/points match what’s in Drive.\")\n",
    "    else:\n",
    "        print(\"\\n❌ MISMATCH detected — do NOT resume building tables with different cuts.\")\n",
    "        if AUTO_ADOPT_SAVED_CUTS and (saved_cuts is not None):\n",
    "            branch_cuts = saved_cuts\n",
    "            branch_pts  = [a for ab in branch_cuts for a in ab]\n",
    "            BRANCH_PTS_MP = [mp.mpc(a.real, a.imag) for a in branch_pts]\n",
    "            print(\"→ Adopted saved branch cuts/points into memory.\")\n",
    "        else:\n",
    "            print(\"Tip: set AUTO_ADOPT_SAVED_CUTS=True to adopt the saved cuts.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433dfcc",
   "metadata": {},
   "source": [
    "\n",
    "## Build ω table (optional; used for anchor selection in training)\n",
    "\n",
    "This is the same idea as your original notebook: evaluate\n",
    "\n",
    "\\[\n",
    "\\omega_k(z) = \\frac{z^k}{\\sqrt{P(z)}}\n",
    "\\]\n",
    "\n",
    "pointwise on the grid. (This is not an integral; it's just the differential value.)\n",
    "We keep the key name `omega_plus` for backward compatibility.\n",
    "\n",
    "> Note: the **magnitude** \\(|\\omega_k|\\) is independent of the sign of \\(\\sqrt{P(z)}\\), so this remains useful for your anchor heuristic even if the sign convention differs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2509fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Build ω (differentials) → Drive (resume-safe, computes all k per grid point)\n",
    "import torch\n",
    "\n",
    "def omega_allk_at_z(z):\n",
    "    \"\"\"Return [omega_0(z), ..., omega_{g-1}(z)] with principal sqrt.\"\"\"\n",
    "    z_mp = mp.mpc(z.real, z.imag)\n",
    "    w = mp.sqrt(P_of_z(z_mp))\n",
    "    inv_w = 1 / w\n",
    "    out = []\n",
    "    z_pow = mp.mpc(1)\n",
    "    for k in range(genus):\n",
    "        out.append(z_pow * inv_w)\n",
    "        z_pow *= z_mp\n",
    "    return out\n",
    "\n",
    "# Initialize or resume\n",
    "if os.path.exists(OMEGAS_PATH):\n",
    "    pkg = torch.load(OMEGAS_PATH, map_location='cpu', weights_only=False)\n",
    "    ensure_config_compatible(pkg)\n",
    "    Om_plus = pkg[\"omega_plus\"]  # (g,H,W) complex\n",
    "    progress = pkg.get(\"progress\", {\"iy_done\": 0})\n",
    "    print(\"Resuming ω from Drive.\")\n",
    "else:\n",
    "    Om_plus = torch.zeros(genus, H, W, dtype=torch.cfloat)\n",
    "    progress = {\"iy_done\": 0}\n",
    "    print(\"Starting fresh ω build.\")\n",
    "\n",
    "SAVE_EVERY_N_ROWS = 1  # safest; raise to reduce I/O\n",
    "\n",
    "t0 = time.time()\n",
    "for iy in range(int(progress[\"iy_done\"]), H):\n",
    "    y = grid_i[iy]\n",
    "    row = np.zeros((genus, W), dtype=np.complex64)\n",
    "    for ix in range(W):\n",
    "        x = grid_r[ix]\n",
    "        z = complex(x, y)\n",
    "        vals = omega_allk_at_z(z)\n",
    "        row[:, ix] = np.array([complex(v) for v in vals], dtype=np.complex64)\n",
    "\n",
    "    Om_plus[:, iy, :] = torch.from_numpy(row)\n",
    "    progress[\"iy_done\"] = iy + 1\n",
    "\n",
    "    if (iy % SAVE_EVERY_N_ROWS) == (SAVE_EVERY_N_ROWS - 1):\n",
    "        payload = {**COMMON_META, \"omega_plus\": Om_plus, \"progress\": progress}\n",
    "        atomic_torch_save(payload, OMEGAS_PATH)\n",
    "\n",
    "# Final save\n",
    "payload = {**COMMON_META, \"omega_plus\": Om_plus, \"progress\": progress}\n",
    "atomic_torch_save(payload, OMEGAS_PATH)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"ω table saved to {OMEGAS_PATH}  | elapsed {t1 - t0:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be371888",
   "metadata": {},
   "source": [
    "\n",
    "## Build AJ integrals for both sheets\n",
    "\n",
    "For each grid point \\(z\\):\n",
    "\n",
    "1. Compute the straight-path lift integral (starting from the base point on sheet 0):\n",
    "   - `I_reached(z)` and the **sheet parity** `parity(z) ∈ {0,1}`.\n",
    "2. Using the bridge vector `B`, define the two-sheet tables:\n",
    "   - If `parity(z)=0`, then `I0(z)=I_reached(z)` and `I1(z)=B-I0(z)`.\n",
    "   - If `parity(z)=1`, then `I1(z)=I_reached(z)` and `I0(z)=B-I1(z)`.\n",
    "\n",
    "This guarantees `I0(z) + I1(z) = B` everywhere (up to numerical error).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Build I0/I1 (integrals) → Drive (resume-safe)\n",
    "import torch\n",
    "\n",
    "# Convert B to torch once for storage; keep python list for arithmetic\n",
    "B_list = [complex(v) for v in B_mp]\n",
    "B_torch = torch.tensor(B_list, dtype=torch.cfloat)\n",
    "\n",
    "# Initialize or resume\n",
    "if os.path.exists(INTEGRALS_PATH):\n",
    "    pkg = torch.load(INTEGRALS_PATH, map_location='cpu', weights_only=False)\n",
    "    ensure_config_compatible(pkg)\n",
    "\n",
    "    I0 = pkg.get(\"I0\", None)\n",
    "    I1 = pkg.get(\"I1\", None)\n",
    "\n",
    "    # Backward compat: older runs might have I_plus only\n",
    "    if I0 is None and \"I_plus\" in pkg:\n",
    "        I0 = pkg[\"I_plus\"]\n",
    "    if I1 is None and \"I_minus\" in pkg:\n",
    "        I1 = pkg[\"I_minus\"]\n",
    "\n",
    "    if I0 is None:\n",
    "        I0 = torch.zeros(genus, H, W, dtype=torch.cfloat)\n",
    "    if I1 is None:\n",
    "        I1 = torch.zeros(genus, H, W, dtype=torch.cfloat)\n",
    "\n",
    "    # Prefer saved B if present\n",
    "    if \"B\" in pkg:\n",
    "        B_torch = pkg[\"B\"].to(torch.cfloat)\n",
    "        B_list = [complex(v) for v in B_torch]\n",
    "        print(\"Loaded B from saved file.\")\n",
    "    else:\n",
    "        print(\"No B in saved file; using newly computed B (will be saved).\")\n",
    "\n",
    "    sheet_parity = pkg.get(\"sheet_parity\", torch.zeros(H, W, dtype=torch.int8))\n",
    "    progress = pkg.get(\"progress\", {\"iy_done\": 0})\n",
    "    print(\"Resuming integrals from Drive.\")\n",
    "else:\n",
    "    I0 = torch.zeros(genus, H, W, dtype=torch.cfloat)\n",
    "    I1 = torch.zeros(genus, H, W, dtype=torch.cfloat)\n",
    "    sheet_parity = torch.zeros(H, W, dtype=torch.int8)\n",
    "    progress = {\"iy_done\": 0}\n",
    "    print(\"Starting fresh integrals build.\")\n",
    "\n",
    "SAVE_EVERY_N_ROWS = 1  # safest\n",
    "\n",
    "B_np = np.array(B_list, dtype=np.complex64)\n",
    "\n",
    "t0 = time.time()\n",
    "start_iy = int(progress[\"iy_done\"])\n",
    "for iy in range(start_iy, H):\n",
    "    y = grid_i[iy]\n",
    "    row0 = np.zeros((genus, W), dtype=np.complex64)\n",
    "    row1 = np.zeros((genus, W), dtype=np.complex64)\n",
    "\n",
    "    for ix in range(W):\n",
    "        x = grid_r[ix]\n",
    "        z = complex(x, y)\n",
    "\n",
    "        I_reached, parity, n_cross = integrate_straight_with_cuts_allk(z)\n",
    "        sheet_parity[iy, ix] = int(parity)\n",
    "\n",
    "        I_reached_c = np.array([complex(v) for v in I_reached], dtype=np.complex64)\n",
    "\n",
    "        if parity == 0:\n",
    "            I0_c = I_reached_c\n",
    "            I1_c = (B_np - I0_c)\n",
    "        else:\n",
    "            I1_c = I_reached_c\n",
    "            I0_c = (B_np - I1_c)\n",
    "\n",
    "        row0[:, ix] = I0_c\n",
    "        row1[:, ix] = I1_c\n",
    "\n",
    "    I0[:, iy, :] = torch.from_numpy(row0)\n",
    "    I1[:, iy, :] = torch.from_numpy(row1)\n",
    "\n",
    "    progress[\"iy_done\"] = iy + 1\n",
    "\n",
    "    if (iy % SAVE_EVERY_N_ROWS) == (SAVE_EVERY_N_ROWS - 1):\n",
    "        payload = {\n",
    "            **COMMON_META,\n",
    "            \"I0\": I0,\n",
    "            \"I1\": I1,\n",
    "            \"B\": B_torch,\n",
    "            \"sheet_parity\": sheet_parity,\n",
    "            # Backward-compat keys:\n",
    "            \"I_plus\": I0,\n",
    "            \"I_minus\": I1,\n",
    "            \"progress\": progress,\n",
    "        }\n",
    "        atomic_torch_save(payload, INTEGRALS_PATH)\n",
    "\n",
    "# Final save\n",
    "payload = {\n",
    "    **COMMON_META,\n",
    "    \"I0\": I0,\n",
    "    \"I1\": I1,\n",
    "    \"B\": B_torch,\n",
    "    \"sheet_parity\": sheet_parity,\n",
    "    \"I_plus\": I0,\n",
    "    \"I_minus\": I1,\n",
    "    \"progress\": progress,\n",
    "}\n",
    "atomic_torch_save(payload, INTEGRALS_PATH)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"I0/I1 tables saved to {INTEGRALS_PATH}  | elapsed {t1 - t0:.1f}s\")\n",
    "\n",
    "# Quick sanity check on a few random points\n",
    "with torch.no_grad():\n",
    "    B_view = B_torch.view(genus, 1, 1)\n",
    "    err = (I0 + I1 - B_view).abs().max().item()\n",
    "print(\"Max |I0 + I1 - B| over table:\", err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bded21",
   "metadata": {},
   "source": [
    "\n",
    "## Notes / knobs you may want to tune\n",
    "\n",
    "- **`mp.mp.dps`**: raise precision if you see instability near branch points.\n",
    "- **`N_GAUSS`**: raise quadrature nodes if you want more accurate integrals.\n",
    "- **Grid size** (`H`,`W`): larger grids cost more but improve bilinear sampling fidelity.\n",
    "- **Cut geometry** (`CUT_RADIUS`, `CUT_JITTER`, `CUT_SEED`): keep fixed across runs if you want reproducibility.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "faithful_aj_lookup_tables.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
