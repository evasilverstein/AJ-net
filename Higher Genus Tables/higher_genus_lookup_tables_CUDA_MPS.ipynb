{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cell 1: Setup, Geometry, and Vectorized Definitions**\n",
    "\n",
    "**Mathematical Context:**\n",
    "This cell establishes the algebraic geometry framework for a hyperelliptic curve of genus $g=30$.\n",
    "\n",
    "1.  **The Curve:** We define a hyperelliptic curve $\\mathcal{C}$ given by the equation:\n",
    "    $$y^2 = \\prod_{i=1}^{2g+2} (x - a_i)$$\n",
    "    where $\\{a_i\\}$ are the $2g+2 = 62$ branch points. These points are generated randomly on a perturbed circle in the complex plane to ensure general position.\n",
    "\n",
    "2.  **Holomorphic Differentials:** The basis for the space of holomorphic differentials $H^0(\\mathcal{C}, \\Omega^1)$ is defined as:\n",
    "    $$\\omega_k = \\frac{z^k}{\\sqrt{\\prod_{i} (z - a_i)}} \\, dz, \\quad \\text{for } k = 0, \\dots, g-1$$\n",
    "\n",
    "3.  **MPS Optimization (Log-Sum-Exp):**\n",
    "    For $g=30$, the denominator involves a polynomial of degree 62. Evaluating this directly causes floating-point overflow. To solve this on the GPU (MPS), we compute the differential in log-space:\n",
    "    $$ \\log(\\omega_k) = k \\log(z) - \\frac{1}{2} \\sum_{i} \\log(z - a_i) $$\n",
    "    $$ \\omega_k = \\exp(\\log(\\omega_k)) $$\n",
    "    This ensures numerical stability using `torch.complex64` or `torch.complex128`.\n",
    "\n",
    "4.  **Vectorized Integration:**\n",
    "    We define a custom Riemann-sum integrator `integrate_row_mps` that computes the path integral $\\int_{P_0}^{z} \\omega_k$ for an entire row of target points $z$ simultaneously, replacing scalar CPU integration methods like `mp.quad`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkYXXBvi5cpi",
    "outputId": "b580a377-c4b5-4414-f56f-1e492e62ce2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Running on Device: mps | Precision: torch.complex128\n",
      "Will save to:\n",
      "  ./AJ_Tables_g30/aj_omegas_genus30.pt \n",
      "  ./AJ_Tables_g30/aj_integrals_genus30.pt\n",
      "genus=30 → cuts=31 ; total branch points=62\n"
     ]
    }
   ],
   "source": [
    "# @title Setup: install, imports, mount Drive, shared config, genus-30 cuts (MPS Version)\n",
    "!pip install -q torch numpy mpmath tqdm\n",
    "\n",
    "import os, time, math, json, numpy as np, torch, mpmath as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Device & Precision Setup\n",
    "# -----------------------------\n",
    "# Mac MPS usually prefers Float32 for speed, but we try Float64/Complex128 for stability if available.\n",
    "# If you get \"MPS not implemented\" errors, switch `dtype` to torch.complex64\n",
    "# DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "DTYPE = torch.complex64 # Genus 30 is heavy; Complex64 is safer for MPS speed/compatibility but can switch to complex128\n",
    "print(f\"Running on Device: {DEVICE} | Precision: {DTYPE}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Drive & save directory\n",
    "# -----------------------------\n",
    "\n",
    "DRIVE_FOLDER = \"AJ_Tables_g30\"\n",
    "# DRIVE_FOLDER = \"AJ_Tables_g100\"\n",
    "\n",
    "\n",
    "SAVE_DIR = f\"./{DRIVE_FOLDER}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "OMEGAS_PATH    = os.path.join(SAVE_DIR, \"aj_omegas_genus30.pt\")\n",
    "INTEGRALS_PATH = os.path.join(SAVE_DIR, \"aj_integrals_genus30.pt\")\n",
    "\n",
    "\n",
    "# OMEGAS_PATH    = os.path.join(SAVE_DIR, \"aj_omegas_genus100.pt\")\n",
    "# INTEGRALS_PATH = os.path.join(SAVE_DIR, \"aj_integrals_genus100.pt\")\n",
    "\n",
    "\n",
    "print(\"Will save to:\\n \", OMEGAS_PATH, \"\\n \", INTEGRALS_PATH)\n",
    "\n",
    "# -----------------------------\n",
    "# Genus & grid\n",
    "# -----------------------------\n",
    "genus = 30\n",
    "# genus = 150\n",
    "H = W = 96\n",
    "r_min, r_max = -6.0, 6.0\n",
    "i_min, i_max = -6.0, 6.0\n",
    "grid_r = np.linspace(r_min, r_max, W).astype(np.float64)\n",
    "grid_i = np.linspace(i_min, i_max, H).astype(np.float64)\n",
    "\n",
    "# We keep mp.dps for the initial setup of branch cuts, but integration will be standard float\n",
    "mp.mp.dps = 50\n",
    "base_point_complex = complex(r_min - 2.0, i_min - 2.0) # Python complex type\n",
    "\n",
    "# -----------------------------\n",
    "# Helper: atomic save\n",
    "# -----------------------------\n",
    "def atomic_torch_save(obj, path):\n",
    "    tmp = path + \".tmp\"\n",
    "    torch.save(obj, tmp)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "# -----------------------------\n",
    "# Genus-30 cuts: (CPU Logic - runs once, keep as is)\n",
    "# -----------------------------\n",
    "def make_hyperelliptic_cuts(g, radius=4.0, jitter=0.25, seed=123):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    m = 2*g + 2\n",
    "    thetas = np.linspace(0, 2*np.pi, m, endpoint=False)\n",
    "    rng.shuffle(thetas)\n",
    "    radii = radius * (1.0 + jitter * (rng.rand(m) - 0.5))\n",
    "    pts = radii * np.exp(1j * thetas)\n",
    "    \n",
    "    scale = max((pts.real.max()-pts.real.min())/(r_max-r_min+1e-6),\n",
    "                (pts.imag.max()-pts.imag.min())/(i_max-i_min+1e-6))\n",
    "    if scale > 0.85:\n",
    "        pts = pts / (scale/0.85)\n",
    "\n",
    "    remaining = list(range(m))\n",
    "    cuts = []\n",
    "    while remaining:\n",
    "        i = remaining.pop(0)\n",
    "        pi = pts[i]\n",
    "        dists = [(j, abs(pi - pts[j])) for j in remaining]\n",
    "        j = min(dists, key=lambda t: t[1])[0]\n",
    "        remaining.remove(j)\n",
    "        a, b = pi, pts[j]\n",
    "        mid = 0.5*(a+b)\n",
    "        a = a + 0.05*(a - mid)\n",
    "        b = b + 0.05*(b - mid)\n",
    "        cuts.append((complex(a), complex(b)))\n",
    "    \n",
    "    if len(cuts) > g+1:\n",
    "        cuts.sort(key=lambda ab: -abs(ab[0]-ab[1]))\n",
    "        cuts = cuts[:g+1]\n",
    "    return cuts\n",
    "\n",
    "branch_cuts = make_hyperelliptic_cuts(genus)\n",
    "branch_pts_list = [a for ab in branch_cuts for a in ab]\n",
    "print(f\"genus={genus} → cuts={len(branch_cuts)} ; total branch points={len(branch_pts_list)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# PREPARE DATA FOR MPS\n",
    "# -----------------------------\n",
    "# Move branch points to GPU once.\n",
    "# shape: (1, 1, num_branch_pts) to allow broadcasting against (Steps, Width, 1)\n",
    "branch_pts_tensor = torch.tensor(branch_pts_list, device=DEVICE, dtype=DTYPE).reshape(1, 1, -1)\n",
    "\n",
    "# -----------------------------\n",
    "# VECTORIZED MATH (PyTorch/MPS)\n",
    "# -----------------------------\n",
    "def omega_torch(k, t_tensor):\n",
    "    \"\"\"\n",
    "    Vectorized calculation of ω_k(t) = t^k / sqrt(prod(t - a_i))\n",
    "    Uses Log-Sum-Exp trick to prevent overflow for Genus 30.\n",
    "    \"\"\"\n",
    "    # t_tensor shape: (Steps, Width)\n",
    "    # branch_pts_tensor shape: (1, 1, 62)\n",
    "    \n",
    "    # 1. Compute differences: (Steps, Width, 62)\n",
    "    diffs = t_tensor.unsqueeze(-1) - branch_pts_tensor\n",
    "    \n",
    "    # 2. Compute Log of denominator: 0.5 * sum(log(diffs))\n",
    "    # We use complex log. torch.log handles complex inputs correctly on recent versions.\n",
    "    log_diffs = torch.log(diffs) \n",
    "    log_denom = 0.5 * torch.sum(log_diffs, dim=-1) # Sum over branch points -> (Steps, Width)\n",
    "    \n",
    "    # 3. Compute Log of numerator: k * log(t)\n",
    "    # (Using log space for numerator too ensures we don't blow up t^30)\n",
    "    log_num = k * torch.log(t_tensor)\n",
    "    \n",
    "    # 4. Combine and exponentiate\n",
    "    # ω = exp(log_num - log_denom)\n",
    "    log_omega = log_num - log_denom\n",
    "    return torch.exp(log_omega)\n",
    "\n",
    "def integrate_row_mps(k, z_row_tensor, base_pt, steps=400):\n",
    "    \"\"\"\n",
    "    Computes integral from base_pt to every point in z_row_tensor simultaneously.\n",
    "    Uses Trapezoidal/Riemann summation.\n",
    "    \n",
    "    z_row_tensor: (W,) complex tensor on MPS\n",
    "    base_pt: scalar complex (python or tensor)\n",
    "    steps: integration resolution (higher = slower but more accurate)\n",
    "    \"\"\"\n",
    "    W_dim = z_row_tensor.size(0)\n",
    "    \n",
    "    # 1. Create Time Steps (0 to 1)\n",
    "    # shape: (steps, 1)\n",
    "    t = torch.linspace(0, 1, steps, device=DEVICE, dtype=z_row_tensor.dtype.real_dtype).unsqueeze(1)\n",
    "    \n",
    "    # 2. Broadcast Path\n",
    "    # Path goes from base_pt to z_row[i]\n",
    "    # diff shape: (W,)\n",
    "    diff = z_row_tensor - base_pt\n",
    "    \n",
    "    # path shape: (steps, W)\n",
    "    # base_pt + t * diff\n",
    "    path = base_pt + (t.type(DTYPE) * diff.unsqueeze(0))\n",
    "    \n",
    "    # 3. Evaluate Derivative (dt)\n",
    "    # dt = diff / steps (constant for straight line)\n",
    "    # shape: (W,)\n",
    "    dt = diff / steps\n",
    "    \n",
    "    # 4. Evaluate Omega on the whole grid\n",
    "    # shape: (steps, W)\n",
    "    vals = omega_torch(k, path)\n",
    "    \n",
    "    # 5. Sum (Trapezoidal approximation: simple sum * dt)\n",
    "    # Result shape: (W,)\n",
    "    # Summing along dim 0 (time steps)\n",
    "    integral = torch.sum(vals, dim=0) * dt\n",
    "    \n",
    "    return integral\n",
    "\n",
    "# -----------------------------\n",
    "# Metadata\n",
    "# -----------------------------\n",
    "COMMON_META = {\n",
    "    \"genus\": genus,\n",
    "    \"branch_cuts\": branch_cuts,\n",
    "    # Store simple numpy/list version in meta, not the tensor\n",
    "    \"branch_pts\": np.array(branch_pts_list, dtype=np.complex128),\n",
    "    \"grid_r\": grid_r, \"grid_i\": grid_i,\n",
    "    \"meta\": {\"dtype\": str(DTYPE), \"base_point\": base_point_complex,\n",
    "             \"grid_shape\": (H, W), \"ranges\": (r_min, r_max, i_min, i_max)}\n",
    "}\n",
    "\n",
    "def ensure_config_compatible(pkg):\n",
    "    assert int(pkg[\"genus\"]) == genus\n",
    "    assert pkg[\"meta\"][\"grid_shape\"] == (H, W)\n",
    "    # Loosen strict equality for floats\n",
    "    assert np.allclose(pkg[\"grid_r\"], grid_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Cell 2: Consistency Verification**\n",
    "\n",
    "**Functional Description:**\n",
    "This cell ensures data integrity when resuming a long computation.\n",
    "\n",
    "1.  **Geometry Check:** It compares the currently generated branch points $\\{a_i\\}_{current}$ with the branch points stored in `aj_integrals_genus30.pt` (if it exists).\n",
    "2.  **Metric:** It checks the Euclidean distance in the complex plane:\n",
    "    $$ \\max_i | a_i^{\\text{saved}} - a_i^{\\text{current}} | < \\epsilon $$\n",
    "3.  **Synchronization:** If a mismatch is found (which would render the integrals invalid), the code can optionally `AUTO_ADOPT` the saved geometry, overwriting the in-memory tensors to match the disk.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5daf8654",
    "outputId": "4e62826e-a795-48f5-b993-32b4677741cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found or INTEGRALS_PATH not defined: ./AJ_Tables_g30/aj_integrals_genus30.pt\n",
      "No saved ω/Ι file found in Drive — looks like a fresh run; nothing to compare.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. File Modification Check\n",
    "if 'INTEGRALS_PATH' in globals() and os.path.exists(INTEGRALS_PATH):\n",
    "    mtime = os.path.getmtime(INTEGRALS_PATH)\n",
    "    print(f\"Last modification time of {os.path.basename(INTEGRALS_PATH)}: {datetime.datetime.fromtimestamp(mtime)}\")\n",
    "else:\n",
    "    print(f\"File not found or INTEGRALS_PATH not defined: {INTEGRALS_PATH if 'INTEGRALS_PATH' in globals() else 'Not Defined'}\")\n",
    "\n",
    "# @title Check/lock branch cuts against saved files (MPS Update)\n",
    "# Toggle: if mismatch is found, automatically replace in-memory cuts/points with the saved ones.\n",
    "AUTO_ADOPT_SAVED_CUTS = False   # set True to auto-fix\n",
    "\n",
    "# Helper: pick a saved file to compare against\n",
    "def pick_saved_path():\n",
    "    cand = []\n",
    "    if 'INTEGRALS_PATH' in globals() and os.path.exists(INTEGRALS_PATH):\n",
    "        cand.append(INTEGRALS_PATH)\n",
    "    if 'OMEGAS_PATH' in globals() and os.path.exists(OMEGAS_PATH):\n",
    "        cand.append(OMEGAS_PATH)\n",
    "    if not cand:\n",
    "        return None\n",
    "    cand.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n",
    "    return cand[0]\n",
    "\n",
    "def np_c128_from_list(lst):\n",
    "    return np.array([complex(z) for z in lst], dtype=np.complex128)\n",
    "\n",
    "# Sanity check for Cell 0/1 variables\n",
    "# Note: We use 'branch_pts_list' from the MPS Cell 1, but we alias it if needed\n",
    "if 'branch_pts_list' in globals():\n",
    "    current_pts_source = branch_pts_list\n",
    "elif 'branch_pts' in globals():\n",
    "    current_pts_source = branch_pts\n",
    "else:\n",
    "    raise RuntimeError(\"Expected `branch_pts_list` or `branch_pts` from Cell 1.\")\n",
    "\n",
    "saved_path = pick_saved_path()\n",
    "\n",
    "if saved_path is None:\n",
    "    print(\"No saved ω/Ι file found in Drive — looks like a fresh run; nothing to compare.\")\n",
    "else:\n",
    "    # Load metadata on CPU\n",
    "    pkg = torch.load(saved_path, map_location=\"cpu\", weights_only=False)\n",
    "    \n",
    "    # Extract saved config\n",
    "    saved_genus = int(pkg.get(\"genus\"))\n",
    "    saved_grid_r = np.array(pkg.get(\"grid_r\"))\n",
    "    saved_grid_i = np.array(pkg.get(\"grid_i\"))\n",
    "    # Handle list vs array in saved files\n",
    "    saved_raw_pts = pkg.get(\"branch_pts\", [])\n",
    "    if isinstance(saved_raw_pts, torch.Tensor):\n",
    "        saved_raw_pts = saved_raw_pts.numpy()\n",
    "    saved_pts = np.array(saved_raw_pts, dtype=np.complex128)\n",
    "    saved_cuts = pkg.get(\"branch_cuts\", None)\n",
    "\n",
    "    curr_pts = np_c128_from_list(current_pts_source)\n",
    "\n",
    "    print(f\"Comparing current session to: {os.path.basename(saved_path)}\")\n",
    "    ok_genus = (saved_genus == genus)\n",
    "    ok_grid  = np.allclose(saved_grid_r, grid_r) and np.allclose(saved_grid_i, grid_i)\n",
    "    \n",
    "    # Robust length check (flatten if needed)\n",
    "    ok_len = (saved_pts.size == curr_pts.size)\n",
    "    \n",
    "    # Robust value check\n",
    "    if ok_len:\n",
    "        saved_flat = saved_pts.flatten()\n",
    "        curr_flat = curr_pts.flatten()\n",
    "        ok_pts = np.allclose(saved_flat.real, curr_flat.real) and \\\n",
    "                 np.allclose(saved_flat.imag, curr_flat.imag)\n",
    "        max_dev = float(np.max(np.abs(saved_flat - curr_flat))) if saved_flat.size else 0.0\n",
    "    else:\n",
    "        ok_pts = False\n",
    "        max_dev = 999.9\n",
    "\n",
    "    print(f\"  genus match : {ok_genus} (saved={saved_genus}, current={genus})\")\n",
    "    print(f\"  grid match  : {ok_grid}\")\n",
    "    if ok_len:\n",
    "        print(f\"  branch pts  : {'MATCH' if ok_pts else 'MISMATCH'} (max |Δ| = {max_dev:.3e})\")\n",
    "    else:\n",
    "        print(f\"  branch pts  : count differs (saved {saved_pts.size}, current {curr_pts.size})\")\n",
    "\n",
    "    if ok_genus and ok_grid and ok_pts:\n",
    "        print(\"\\n✅ SAFE to resume: cuts/points match what’s in Drive.\")\n",
    "    else:\n",
    "        print(\"\\n❌ MISMATCH detected — do NOT resume building tables with different cuts.\")\n",
    "        \n",
    "        if AUTO_ADOPT_SAVED_CUTS and (saved_cuts is not None):\n",
    "            # 1. Update CPU lists\n",
    "            branch_cuts = saved_cuts\n",
    "            branch_pts_list = [a for ab in branch_cuts for a in ab]\n",
    "            \n",
    "            # 2. IMPORTANT: Update the MPS Tensor used by the integrator\n",
    "            # (Re-run the tensor creation line from Cell 1)\n",
    "            if 'DEVICE' in globals() and 'DTYPE' in globals():\n",
    "                branch_pts_tensor = torch.tensor(branch_pts_list, device=DEVICE, dtype=DTYPE).reshape(1, 1, -1)\n",
    "                print(\"→ Updated `branch_pts_tensor` on MPS device.\")\n",
    "            \n",
    "            print(\"→ Adopted the saved branch cuts/points into memory. You can now safely resume.\")\n",
    "        else:\n",
    "            print(\"Tip: set AUTO_ADOPT_SAVED_CUTS=True at the top of this cell to adopt the saved cuts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMOStSPIaJwr",
    "outputId": "47e92bac-ccd3-4603-ce77-12357396ccdb"
   },
   "source": [
    "\n",
    "\n",
    "### **Cell 3: Evaluation of Differentials ($\\omega$)**\n",
    "\n",
    "**Mathematical Context:**\n",
    "This cell computes the raw values of the differential forms on a discrete 2D grid.\n",
    "\n",
    "1.  **The Grid:** We define a lattice $\\Lambda$ of size $H \\times W$ in the complex plane $\\mathbb{C}$.\n",
    "2.  **Computation:** For every genus index $k \\in \\{0, \\dots, 29\\}$ and every spatial point $z_{xy} \\in \\Lambda$, we compute:\n",
    "    $$ V_{k, y, x} = \\frac{z_{xy}^k}{y(z_{xy})} $$\n",
    "3.  **Vectorization:**\n",
    "    Instead of looping pixel-by-pixel, the code processes an entire row $y$ (of width $W$) as a single GPU tensor operation.\n",
    "4.  **Output:** A tensor `Om_plus` of shape $(30, H, W)$ is saved to disk.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIX0FXGB5xPA",
    "outputId": "0f39b930-933c-427b-af8b-6d82c77742cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fresh ω build.\n",
      "Building ω[0] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[0]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1000.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[1] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[1]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1805.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[2] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[2]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1888.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[3] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[3]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1921.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[4] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[4]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 2007.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[5] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[5]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 2108.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[6] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[6]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 2151.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[7] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[7]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 2081.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[8] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[8]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 2113.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[9] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[9]: 100%|███████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 2062.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[10] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[10]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1796.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[11] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[11]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1106.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[12] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[12]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1636.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[13] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[13]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1600.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[14] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[14]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1732.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[15] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[15]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1887.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[16] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[16]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1860.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[17] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[17]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1891.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[18] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[18]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1792.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[19] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[19]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1819.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[20] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[20]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1820.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[21] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[21]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1708.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[22] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[22]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1815.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[23] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[23]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1663.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[24] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[24]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1488.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[25] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[25]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1827.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[26] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[26]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1932.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[27] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[27]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1961.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[28] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[28]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 1981.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ω[29] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "omega[29]: 100%|██████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 2031.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ω table saved to ./AJ_Tables_g30/aj_omegas_genus30.pt  | elapsed 1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Build ω (differentials) for g=30 → Drive (MPS Optimized)\n",
    "import torch\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Initialize or Resume\n",
    "# -----------------------------\n",
    "if os.path.exists(OMEGAS_PATH):\n",
    "    pkg = torch.load(OMEGAS_PATH, map_location='cpu', weights_only=False)\n",
    "    # Ensure compatibility\n",
    "    if \"meta\" in pkg:\n",
    "        saved_sh = pkg[\"meta\"].get(\"grid_shape\", (0,0))\n",
    "        if saved_sh != (H, W):\n",
    "            print(f\"Warning: Saved shape {saved_sh} differs from current {(H,W)}.\")\n",
    "    \n",
    "    Om_plus = pkg[\"omega_plus\"]                  # (g, H, W) complex\n",
    "    progress = pkg.get(\"progress\", {\"iy_done\": [0]*genus, \"k_done\": 0})\n",
    "    print(\"Resuming ω from Drive.\")\n",
    "else:\n",
    "    # Storage uses standard complex64 to save RAM/Disk\n",
    "    Om_plus = torch.zeros(genus, H, W, dtype=torch.complex64)\n",
    "    progress = {\"iy_done\": [0]*genus, \"k_done\": 0}\n",
    "    print(\"Starting fresh ω build.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. MPS Setup for this cell\n",
    "# -----------------------------\n",
    "# Manually determine the real component type to avoid attribute errors\n",
    "if DTYPE == torch.complex128:\n",
    "    REAL_DTYPE = torch.float64\n",
    "else:\n",
    "    REAL_DTYPE = torch.float32\n",
    "\n",
    "# Move grid_r to GPU once\n",
    "grid_r_tensor = torch.tensor(grid_r, device=DEVICE, dtype=REAL_DTYPE)\n",
    "\n",
    "SAVE_EVERY_N_ROWS = 20  # Save less frequently since compute is faster\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Main Loop\n",
    "# -----------------------------\n",
    "for k in range(progress[\"k_done\"], genus):\n",
    "    start_iy = int(progress[\"iy_done\"][k])\n",
    "    if start_iy >= H:\n",
    "        print(f\"ω[{k}] already complete ({H} rows).\")\n",
    "        progress[\"k_done\"] = k+1\n",
    "        continue\n",
    "\n",
    "    print(f\"Building ω[{k}] rows {start_iy}..{H-1}\")\n",
    "    rows_since_save = 0\n",
    "    \n",
    "    # Iterate over rows (Y axis)\n",
    "    for iy in tqdm(range(start_iy, H), desc=f\"omega[{k}]\"):\n",
    "        y_val = grid_i[iy]\n",
    "        \n",
    "        # --- VECTORIZED BLOCK START ---\n",
    "        \n",
    "        # 1. Create the Complex Row Z = x + iy on MPS\n",
    "        # shape: (W,)\n",
    "        Z_row = torch.complex(grid_r_tensor, torch.full_like(grid_r_tensor, y_val))\n",
    "        \n",
    "        # 2. Compute Omega using the GPU-optimized function from Cell 1\n",
    "        # returns shape (W,) on MPS\n",
    "        row_vals = omega_torch(k, Z_row)\n",
    "        \n",
    "        # 3. Move result to CPU and store\n",
    "        Om_plus[k, iy, :] = row_vals.cpu()\n",
    "        \n",
    "        # --- VECTORIZED BLOCK END ---\n",
    "\n",
    "        progress[\"iy_done\"][k] = iy + 1\n",
    "        rows_since_save += 1\n",
    "\n",
    "        # Periodic Save\n",
    "        if rows_since_save >= SAVE_EVERY_N_ROWS:\n",
    "            payload = {**COMMON_META, \"omega_plus\": Om_plus, \"progress\": progress}\n",
    "            atomic_torch_save(payload, OMEGAS_PATH)\n",
    "            rows_since_save = 0\n",
    "\n",
    "    # Finalize this k\n",
    "    progress[\"k_done\"] = k+1\n",
    "    payload = {**COMMON_META, \"omega_plus\": Om_plus, \"progress\": progress}\n",
    "    atomic_torch_save(payload, OMEGAS_PATH)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"ω table saved to {OMEGAS_PATH}  | elapsed {t1 - t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Cell 4: Computation of the Abel-Jacobi Map (Integrals)**\n",
    "\n",
    "**Mathematical Context:**\n",
    "This cell performs the numerical integration required for the Abel-Jacobi map.\n",
    "\n",
    "1.  **The Integral:** We compute the period integrals from a fixed base point $P_0$ to every point $z$ on the grid:\n",
    "    $$ I_k(z) = \\int_{P_0}^{z} \\omega_k = \\int_{P_0}^{z} \\frac{t^k}{\\sqrt{P(t)}} dt $$\n",
    "\n",
    "2.  **Path:** The integration path is a straight line segment defined by the parameterization:\n",
    "    $$ \\gamma(t) = P_0 + t(z - P_0), \\quad t \\in [0, 1] $$\n",
    "\n",
    "3.  **Numerical Method (Trapezoidal Rule on MPS):**\n",
    "    The integral is approximated using a discrete summation with $N$ steps (default 500):\n",
    "    $$ \\int_{P_0}^{z} \\omega_k \\approx \\frac{z - P_0}{N} \\sum_{j=0}^{N} \\omega_k\\left( P_0 + \\frac{j}{N}(z - P_0) \\right) $$\n",
    "    \n",
    "    This is executed in parallel for all $z$ in a row and all steps $j$ using matrix operations on the GPU.\n",
    "\n",
    "4.  **Output:** A tensor `I_plus` of shape $(30, H, W)$, representing the partially computed Abel map values.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2CoKRKn7cCY",
    "outputId": "aa4c0ef2-a91d-41d5-c0ad-7452f36c83b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fresh integrals build.\n",
      "Building I[0] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[0]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 354.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[1] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[1]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 628.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[2] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[2]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 692.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[3] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[3]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 689.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[4] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[4]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 670.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[5] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[5]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 657.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[6] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[6]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 654.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[7] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[7]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 702.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[8] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[8]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 705.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[9] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[9]   : 100%|█████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 708.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[10] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[10]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 699.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[11] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[11]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 681.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[12] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[12]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 650.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[13] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[13]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 635.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[14] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[14]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 677.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[15] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[15]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 686.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[16] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[16]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 692.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[17] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[17]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 696.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[18] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[18]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 693.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[19] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[19]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 688.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[20] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[20]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 661.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[21] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[21]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 697.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[22] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[22]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 686.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[23] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[23]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 680.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[24] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[24]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 694.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[25] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[25]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 682.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[26] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[26]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 702.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[27] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[27]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 647.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[28] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[28]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 632.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building I[29] rows 0..95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I[29]   : 100%|████████████████████████████████████████████████████████████████████████████████████████| 96/96 [00:00<00:00, 595.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I table saved to ./AJ_Tables_g30/aj_integrals_genus30.pt  | elapsed 4.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Build I (integrals) for g=30 → Drive (MPS Optimized)\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# 0. HOTFIX: Redefine the Integrator to fix 'real_dtype' error\n",
    "# -----------------------------\n",
    "def integrate_row_mps(k, z_row_tensor, base_pt, steps=400):\n",
    "    \"\"\"\n",
    "    Computes integral from base_pt to every point in z_row_tensor simultaneously.\n",
    "    Overwrites the Cell 1 version to fix AttributeError on older PyTorch versions.\n",
    "    \"\"\"\n",
    "    # 1. Determine correct real dtype manually\n",
    "    if z_row_tensor.dtype == torch.complex128:\n",
    "        rdtype = torch.float64\n",
    "    else:\n",
    "        rdtype = torch.float32\n",
    "\n",
    "    # 2. Create Time Steps (0 to 1)\n",
    "    # shape: (steps, 1)\n",
    "    t = torch.linspace(0, 1, steps, device=z_row_tensor.device, dtype=rdtype).unsqueeze(1)\n",
    "    \n",
    "    # 3. Broadcast Path\n",
    "    diff = z_row_tensor - base_pt\n",
    "    \n",
    "    # path shape: (steps, W)\n",
    "    # We cast t to the complex type of z_row_tensor to ensure smooth broadcasting\n",
    "    path = base_pt + (t.type(z_row_tensor.dtype) * diff.unsqueeze(0))\n",
    "    \n",
    "    # 4. Evaluate Derivative (dt)\n",
    "    dt = diff / steps\n",
    "    \n",
    "    # 5. Evaluate Omega on the whole grid\n",
    "    vals = omega_torch(k, path)\n",
    "    \n",
    "    # 6. Sum (Trapezoidal approximation)\n",
    "    integral = torch.sum(vals, dim=0) * dt\n",
    "    return integral\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Initialize or Resume\n",
    "# -----------------------------\n",
    "if os.path.exists(INTEGRALS_PATH):\n",
    "    pkg = torch.load(INTEGRALS_PATH, map_location='cpu', weights_only=False)\n",
    "    ensure_config_compatible(pkg)\n",
    "    I_plus = pkg[\"I_plus\"]                       # (g, H, W) complex\n",
    "    progress = pkg.get(\"progress\", {\"iy_done\": [0]*genus, \"k_done\": 0})\n",
    "    print(\"Resuming integrals from Drive.\")\n",
    "else:\n",
    "    # Storage on CPU using complex64 to save RAM\n",
    "    I_plus = torch.zeros(genus, H, W, dtype=torch.complex64)\n",
    "    progress = {\"iy_done\": [0]*genus, \"k_done\": 0}\n",
    "    print(\"Starting fresh integrals build.\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. MPS Configuration\n",
    "# -----------------------------\n",
    "SAVE_EVERY_N_ROWS = 10  # Save less often now that it's faster\n",
    "STEPS_QUALITY = 500     # Integration steps (Riemann sum).\n",
    "\n",
    "# Determine real dtype manually for the grid\n",
    "if DTYPE == torch.complex128:\n",
    "    REAL_DTYPE = torch.float64\n",
    "else:\n",
    "    REAL_DTYPE = torch.float32\n",
    "\n",
    "# Prepare grid X coordinates on GPU once\n",
    "grid_r_tensor = torch.tensor(grid_r, device=DEVICE, dtype=REAL_DTYPE)\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Main Loop\n",
    "# -----------------------------\n",
    "for k in range(progress[\"k_done\"], genus):\n",
    "    start_iy = int(progress[\"iy_done\"][k])\n",
    "    if start_iy >= H:\n",
    "        print(f\"I[{k}] already complete ({H} rows).\")\n",
    "        progress[\"k_done\"] = k+1\n",
    "        continue\n",
    "\n",
    "    print(f\"Building I[{k}] rows {start_iy}..{H-1}\")\n",
    "    rows_since_save = 0\n",
    "    \n",
    "    # Iterate over rows (Y axis)\n",
    "    for iy in tqdm(range(start_iy, H), desc=f\"I[{k}]   \"):\n",
    "        y_val = grid_i[iy]\n",
    "        \n",
    "        # --- VECTORIZED BLOCK START ---\n",
    "        \n",
    "        # 1. Create the Complex Row Z = x + iy on MPS\n",
    "        # shape: (W,)\n",
    "        Z_row = torch.complex(grid_r_tensor, torch.full_like(grid_r_tensor, y_val))\n",
    "        \n",
    "        # 2. Compute Integral for the whole row\n",
    "        # Now uses the patched integrate_row_mps defined above\n",
    "        row_vals = integrate_row_mps(k, Z_row, base_point_complex, steps=STEPS_QUALITY)\n",
    "        \n",
    "        # 3. Move result to CPU and store\n",
    "        I_plus[k, iy, :] = row_vals.cpu()\n",
    "        \n",
    "        # --- VECTORIZED BLOCK END ---\n",
    "\n",
    "        progress[\"iy_done\"][k] = iy + 1\n",
    "        rows_since_save += 1\n",
    "\n",
    "        # Periodic Save\n",
    "        if rows_since_save >= SAVE_EVERY_N_ROWS:\n",
    "            payload = {**COMMON_META, \"I_plus\": I_plus, \"progress\": progress}\n",
    "            atomic_torch_save(payload, INTEGRALS_PATH)\n",
    "            rows_since_save = 0\n",
    "\n",
    "    # Finalize this k\n",
    "    progress[\"k_done\"] = k+1\n",
    "    payload = {**COMMON_META, \"I_plus\": I_plus, \"progress\": progress}\n",
    "    atomic_torch_save(payload, INTEGRALS_PATH)\n",
    "\n",
    "t1 = time.time()\n",
    "print(f\"I table saved to {INTEGRALS_PATH}  | elapsed {t1 - t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qMJ7R1WOLJ4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
