{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we start to scale up, using the pre-computed integrals for genus 30 (but not yet pre-computed periods, instead we mock up the periodicity along the original axes). This already beats not only the 2d projection model but also is comparable to  the 2g x 2g model with many fewer parameters.  [Depending on the AJ version it can do a bit better in fact (maybe periodicity helps, beyond just sheer dimensionality of the layer).]  \n",
        "\n"
      ],
      "metadata": {
        "id": "OWzNjEzKqd3p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1gYMuYlSxM2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOBwLptQbR-M",
        "outputId": "d07658ef-995c-4f7d-bc4a-53eddf8303db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loaded: genus=30, grid=(96x96)\n"
          ]
        }
      ],
      "source": [
        "# @title Load from Drive\n",
        "!pip install -q torch torchvision numpy\n",
        "\n",
        "import os, math, json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from google.colab import drive\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ===========================\n",
        "# 1) Drive + Paths (match Notebook 1)\n",
        "# ===========================\n",
        "DRIVE_FOLDER = \"AJ_Tables_g30\"  # same as Notebook 1\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "SAVE_DIR = f\"/content/drive/MyDrive/{DRIVE_FOLDER}\"\n",
        "INTEGRALS_PATH = os.path.join(SAVE_DIR, \"aj_integrals_genus30.pt\")\n",
        "OMEGAS_PATH    = os.path.join(SAVE_DIR, \"aj_omegas_genus30.pt\")\n",
        "assert os.path.exists(INTEGRALS_PATH), \"Integrals file not found in Drive\"\n",
        "assert os.path.exists(OMEGAS_PATH),    \"Omegas file not found in Drive\"\n",
        "\n",
        "\n",
        "\n",
        "# ===========================\n",
        "# 2) Load tables\n",
        "# ===========================\n",
        "ints = torch.load(INTEGRALS_PATH, map_location='cpu', weights_only=False)\n",
        "omeg = torch.load(OMEGAS_PATH,    map_location='cpu', weights_only=False)\n",
        "\n",
        "# ints = torch.load(INTEGRALS_PATH, map_location='cpu')  ### old version\n",
        "# omeg = torch.load(OMEGAS_PATH,    map_location='cpu')\n",
        "\n",
        "genus       = int(ints[\"genus\"])\n",
        "grid_r_np   = np.array(ints[\"grid_r\"])\n",
        "grid_i_np   = np.array(ints[\"grid_i\"])\n",
        "branch_pts  = np.array(ints[\"branch_pts\"])\n",
        "I_plus      = ints[\"I_plus\"]            # (g, H, W) complex\n",
        "Om_plus     = omeg[\"omega_plus\"]        # (g, H, W) complex\n",
        "\n",
        "H, W = I_plus.shape[-2:]\n",
        "grid_r = torch.tensor(grid_r_np, dtype=torch.float32)\n",
        "grid_i = torch.tensor(grid_i_np, dtype=torch.float32)\n",
        "branch_pts_t = torch.tensor(branch_pts)   # complex128 → complex64 in torch if needed\n",
        "\n",
        "print(f\"Loaded: genus={genus}, grid=({H}x{W})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Base class AJMNIST_Anchored (needed for PeriodicHead)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AJMNIST_Anchored(nn.Module):\n",
        "    \"\"\"\n",
        "    Anchored AJ model:\n",
        "      - conv trunk (1→64)\n",
        "      - learned per-point embeddings (g×embed_dim)\n",
        "      - shared point_head producing (x,y, sheet_logit) for each point\n",
        "      - per-point bias initialized to ω-aware anchors\n",
        "      - AJGridActivationNorm does lookup, standardization, sheet sign, and sum\n",
        "      - classifier: linear 2g→10\n",
        "    \"\"\"\n",
        "    def __init__(self, genus, I_plus, Om_plus, grid_r, grid_i, branch_pts,\n",
        "                 anchors_xy, mu, sigma, embed_dim=8):\n",
        "        super().__init__()\n",
        "        self.genus = genus\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.AdaptiveAvgPool2d((1,1))\n",
        "        )\n",
        "        self.embed = nn.Parameter(torch.empty(genus, embed_dim))\n",
        "        nn.init.uniform_(self.embed, -2.0, 2.0)\n",
        "\n",
        "        # shared point_head (no bias) + per-point bias\n",
        "        self.point_head = nn.Linear(64 + embed_dim, 3, bias=False)\n",
        "        nn.init.xavier_uniform_(self.point_head.weight)\n",
        "        self.point_bias = nn.Parameter(torch.zeros(genus, 3))\n",
        "\n",
        "        # AJ activation with normalization\n",
        "        self.aj = AJGridActivationNorm(I_plus, Om_plus, grid_r, grid_i, branch_pts, mu, sigma)\n",
        "        self.classifier = nn.Linear(2*genus, 10)\n",
        "\n",
        "        # ω-aware initialization for biases\n",
        "        rmin, rmax = float(grid_r.min()), float(grid_r.max())\n",
        "        imin, imax = float(grid_i.min()), float(grid_i.max())\n",
        "        def logit(p): return float(torch.log(p/(1-p)))\n",
        "        with torch.no_grad():\n",
        "            for i in range(genus):\n",
        "                x0, y0 = float(anchors_xy[i,0]), float(anchors_xy[i,1])\n",
        "                px = (x0 - rmin) / (rmax - rmin)\n",
        "                py = (y0 - imin) / (imax - imin)\n",
        "                self.point_bias[i, 0] = logit(torch.tensor(px))\n",
        "                self.point_bias[i, 1] = logit(torch.tensor(py))\n",
        "                target_sign = 0.8 if (i % 2 == 0) else -0.8\n",
        "                self.point_bias[i, 2] = float(torch.atanh(torch.tensor(target_sign)))\n",
        "\n",
        "    def forward(self, x, return_aux=False):\n",
        "        B = x.size(0)\n",
        "        h = self.conv(x).view(B, -1)\n",
        "        h_exp = h.unsqueeze(1).expand(-1, self.genus, -1)\n",
        "        emb   = self.embed.unsqueeze(0).expand(B, -1, -1)\n",
        "        inp   = torch.cat([h_exp, emb], dim=2)\n",
        "\n",
        "        out   = self.point_head(inp) + self.point_bias.unsqueeze(0)  # (B,g,3)\n",
        "        raw_xy, sheet_logits = out[..., :2], out[..., 2]\n",
        "        coords, aux = self.aj(raw_xy, sheet_logits, return_aux=True)\n",
        "        logits = self.classifier(coords)\n",
        "        if return_aux:\n",
        "            return logits, aux\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "ZdfC2DNCzLXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title AJ model with ω-aware init + AJ normalization + learnable gain\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def _pack_complex_table(table_gHW: torch.Tensor) -> torch.Tensor:\n",
        "    re, im = table_gHW.real, table_gHW.imag\n",
        "    return torch.cat([re, im], dim=0).unsqueeze(0).contiguous()  # (1, 2g, H, W)\n",
        "\n",
        "class AJGridActivationNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    AJ lookup with:\n",
        "      - bilinear sampling\n",
        "      - continuous sheet sign via tanh\n",
        "      - channel-wise standardization: (I - mu)/sigma\n",
        "      - learnable global gain gamma\n",
        "      - boundary/branch penalties (for diagnostics/regularization)\n",
        "    \"\"\"\n",
        "    def __init__(self, I_plus, Om_plus, grid_r, grid_i, branch_pts, mu, sigma):\n",
        "        super().__init__()\n",
        "        self.g = I_plus.shape[0]\n",
        "        self.register_buffer(\"I_plus\",  _pack_complex_table(I_plus))\n",
        "        self.register_buffer(\"Om_plus\", _pack_complex_table(Om_plus))\n",
        "\n",
        "        # stats\n",
        "        self.register_buffer(\"mu\",    mu.view(1, 1, -1))     # (1,1,2g)\n",
        "        self.register_buffer(\"sigma\", sigma.view(1, 1, -1))  # (1,1,2g)\n",
        "        self.gamma = nn.Parameter(torch.tensor(1.0))         # learnable gain\n",
        "\n",
        "        # bounds\n",
        "        self.register_buffer(\"r_min\", torch.tensor(float(grid_r.min())))\n",
        "        self.register_buffer(\"r_max\", torch.tensor(float(grid_r.max())))\n",
        "        self.register_buffer(\"i_min\", torch.tensor(float(grid_i.min())))\n",
        "        self.register_buffer(\"i_max\", torch.tensor(float(grid_i.max())))\n",
        "\n",
        "        # branch points\n",
        "        self.register_buffer(\"bp_real\", branch_pts.real.float())\n",
        "        self.register_buffer(\"bp_imag\", branch_pts.imag.float())\n",
        "\n",
        "    def _map_raw_to_bounds(self, raw_xy):\n",
        "        # sigmoid mapping into box\n",
        "        xr = self.r_min + (self.r_max - self.r_min) * torch.sigmoid(raw_xy[..., 0])\n",
        "        yi = self.i_min + (self.i_max - self.i_min) * torch.sigmoid(raw_xy[..., 1])\n",
        "        return xr, yi\n",
        "\n",
        "    def _norm_to_grid(self, xr, yi):\n",
        "        gx = 2.0 * (xr - self.r_min) / (self.r_max - self.r_min) - 1.0\n",
        "        gy = 2.0 * (yi - self.i_min) / (self.i_max - self.i_min) - 1.0\n",
        "        return gx, gy\n",
        "\n",
        "    def forward(self, raw_xy: torch.Tensor, sheet_logits: torch.Tensor, return_aux=True):\n",
        "        B, g, _ = raw_xy.shape\n",
        "        assert g == self.g\n",
        "\n",
        "        xr, yi = self._map_raw_to_bounds(raw_xy)\n",
        "        gx, gy = self._norm_to_grid(xr, yi)\n",
        "        grid = torch.stack([gx, gy], dim=-1).view(B*g, 1, 1, 2)\n",
        "\n",
        "        # Sample integrals and standardize\n",
        "        I = F.grid_sample(self.I_plus.expand(B*g, -1, -1, -1),\n",
        "                          grid, mode=\"bilinear\", align_corners=True).view(B, g, -1)\n",
        "        I_std = (I - self.mu) / self.sigma                        # (B, g, 2g)\n",
        "\n",
        "        # Continuous sheet sign (initialized away from 0 in the constructor below)\n",
        "        #sign = torch.tanh(sheet_logits).unsqueeze(-1)             # (B, g, 1)\n",
        "        # inside AJGridActivationNorm.forward(...)\n",
        "\n",
        "        sign = torch.tanh(sheet_logits).unsqueeze(-1)  # (B,g,1)\n",
        "        contrib = sign * I_std\n",
        "        coords  = self.gamma * contrib.sum(dim=1)      # (B,2g)\n",
        "\n",
        "\n",
        "        # contrib = sign * I_std\n",
        "        # coords = self.gamma * contrib.sum(dim=1)                  # (B, 2g)\n",
        "\n",
        "        aux = None\n",
        "        if return_aux:\n",
        "            margin = 0.95\n",
        "            bpen = ((gx.abs() - margin).clamp_min(0)**2 +\n",
        "                    (gy.abs() - margin).clamp_min(0)**2).mean()\n",
        "\n",
        "            dx = xr.unsqueeze(-1) - self.bp_real\n",
        "            dy = yi.unsqueeze(-1) - self.bp_imag\n",
        "            d2 = dx*dx + dy*dy\n",
        "            tau = 0.07\n",
        "            rpen = torch.exp(-d2 / (2*tau*tau)).mean()\n",
        "\n",
        "            # aux = {\"bound_penalty\": bpen, \"branch_penalty\": rpen,\n",
        "            #        \"gx\": gx, \"gy\": gy, \"x\": xr, \"y\": yi}\n",
        "            # inside AJGridActivationNorm.forward(...), in the return_aux block\n",
        "            aux = {\n",
        "                \"x\": xr, \"y\": yi, \"gx\": gx, \"gy\": gy,\n",
        "                \"bound_penalty\": bpen, \"branch_penalty\": rpen,\n",
        "                \"sheet_sign\": sign.squeeze(-1)   # keep this\n",
        "                # \"omega_channels\": Om  <-- delete this line\n",
        "            }\n",
        "\n",
        "            # aux = {\n",
        "            #     \"x\": xr, \"y\": yi, \"gx\": gx, \"gy\": gy,\n",
        "            #     \"bound_penalty\": bpen, \"branch_penalty\": rpen,\n",
        "            #     \"omega_channels\": Om,\n",
        "            #     \"sheet_sign\": sign.squeeze(-1)  # <-- add this line\n",
        "            # }\n",
        "        return coords, aux\n",
        "\n",
        "def logit(p):  # inverse sigmoid\n",
        "    p = np.clip(p, 1e-6, 1-1e-6)\n",
        "    return float(np.log(p/(1-p)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "o_xhCmbWBww6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AJ periodic head WITHOUT tau: axis-aligned Fourier features (global K)\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "\n",
        "class TorusFeatures(nn.Module):\n",
        "    def __init__(self, dim: int, K: int = 2, freqs=None, learnable: bool = False):\n",
        "        super().__init__()\n",
        "        if freqs is None:\n",
        "            freqs = torch.tensor([0.5, 1.0], dtype=torch.float32)[:K]\n",
        "        else:\n",
        "            freqs = torch.as_tensor(freqs, dtype=torch.float32)[:K]\n",
        "        if learnable:\n",
        "            self.freqs = nn.Parameter(freqs)\n",
        "        else:\n",
        "            self.register_buffer(\"freqs\", freqs)\n",
        "        self.dim, self.K = dim, len(freqs)\n",
        "    def forward(self, u):\n",
        "        B, D = u.shape\n",
        "        f = (self.freqs if isinstance(self.freqs, torch.Tensor) else torch.as_tensor(self.freqs)).view(1,1,-1).to(u.device)\n",
        "        ang = u.unsqueeze(-1) * f\n",
        "        return torch.cat([torch.cos(ang), torch.sin(ang)], dim=-1).view(B, D*2*self.K)\n",
        "\n",
        "class AJMNIST_AxisPeriodic(nn.Module):\n",
        "    \"\"\"\n",
        "    Drop-in head: AJ (anchored+norm) → axis-aligned periodic features → classifier\n",
        "    Expects you already have AJMNIST_Anchored and AJGridActivationNorm defined.\n",
        "    \"\"\"\n",
        "    def __init__(self, genus, I_plus, Om_plus, grid_r, grid_i, branch_pts,\n",
        "                 anchors_xy, mu, sigma, embed_dim=8, K=2, learnable_freqs=False):\n",
        "        super().__init__()\n",
        "        self.base = AJMNIST_Anchored(genus, I_plus, Om_plus, grid_r, grid_i, branch_pts,\n",
        "                                     anchors_xy, mu, sigma, embed_dim=embed_dim)\n",
        "        D = 2*genus\n",
        "        self.torus = TorusFeatures(D, K=K, learnable=learnable_freqs)\n",
        "        self.classifier = nn.Linear(D*2*K, 10)\n",
        "    @property\n",
        "    def genus(self): return self.base.genus\n",
        "    def forward(self, x, return_aux=False):\n",
        "        B = x.size(0)\n",
        "        h = self.base.conv(x).view(B, -1)\n",
        "        h_exp = h.unsqueeze(1).expand(-1, self.genus, -1)\n",
        "        emb   = self.base.embed.unsqueeze(0).expand(B, -1, -1)\n",
        "        out   = self.base.point_head(torch.cat([h_exp, emb], dim=2)) + self.base.point_bias.unsqueeze(0)\n",
        "        raw_xy, sheet_logits = out[..., :2], out[..., 2]\n",
        "        coords, aux = self.base.aj(raw_xy, sheet_logits, return_aux=True)  # (B, 2g)\n",
        "        feats = self.torus(coords)\n",
        "        logits = self.classifier(feats)\n",
        "        if return_aux: return logits, aux\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "gQ2Dt5Z3Bw2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Compute ω-aware anchors and AJ normalization\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 1) Build a scalar \"ω-strength\" map on the grid to avoid dead-gradient regions\n",
        "#    Use sum_k |ω_k| (or |ω_k|^2); both work similarly.\n",
        "with torch.no_grad():\n",
        "    # Om_plus: (g, H, W) complex\n",
        "    Wmap = Om_plus.abs().sum(dim=0)  # (H, W)\n",
        "    Wmap_np = Wmap.cpu().numpy()\n",
        "\n",
        "# 2) Mask out boundaries and branch points (stay away from peaks/singularities too)\n",
        "H, W = Wmap_np.shape\n",
        "gy = np.linspace(-1, 1, H)[:, None]\n",
        "gx = np.linspace(-1, 1, W)[None, :]\n",
        "edge_mask = (np.abs(gx) < 0.92) & (np.abs(gy) < 0.92)\n",
        "\n",
        "# Distance from branch points in grid coordinates\n",
        "grid_x = grid_r_np[None, :].repeat(H, axis=0)  # (H,W)\n",
        "grid_y = grid_i_np[:, None].repeat(W, axis=1)  # (H,W)\n",
        "bp_real = np.real(branch_pts).reshape(-1, 1, 1)\n",
        "bp_imag = np.imag(branch_pts).reshape(-1, 1, 1)\n",
        "d2 = (grid_x - bp_real)**2 + (grid_y - bp_imag)**2  # (P, H, W)\n",
        "bp_mask = (d2.min(axis=0) > 0.25)  # keep points with dist > ~0.5\n",
        "\n",
        "mask = edge_mask & bp_mask\n",
        "\n",
        "# 3) Pick g anchor points among top-quantile ω regions, well separated\n",
        "score = np.where(mask, Wmap_np, -np.inf)\n",
        "th = np.quantile(score[score > -np.inf], 0.85)  # top 15% by ω-strength\n",
        "cand = np.argwhere(score >= th)                 # list of (iy, ix)\n",
        "\n",
        "# Farthest-point sampling to pick 'genus' diverse anchors\n",
        "def farthest_k(points_hw, k):\n",
        "    pts = points_hw.copy()\n",
        "    # Start from the global maximum\n",
        "    start = pts[np.argmax(score[tuple(pts.T)])]\n",
        "    chosen = [start]\n",
        "    if k == 1: return np.array(chosen)\n",
        "    # Precompute physical coordinates for distances\n",
        "    coords = np.stack([grid_x[tuple(pts.T)], grid_y[tuple(pts.T)]], axis=1)\n",
        "    c0 = np.array([grid_x[start[0], start[1]], grid_y[start[0], start[1]]])[None, :]\n",
        "    mind = np.sum((coords - c0)**2, axis=1)\n",
        "    for _ in range(1, k):\n",
        "        j = np.argmax(mind)\n",
        "        chosen.append(pts[j])\n",
        "        cj = coords[j][None, :]\n",
        "        mind = np.minimum(mind, np.sum((coords - cj)**2, axis=1))\n",
        "    return np.array(chosen)\n",
        "\n",
        "anchors_hw = farthest_k(cand, genus)  # shape (g, 2) with (iy, ix)\n",
        "\n",
        "# 4) Convert anchors to (x0, y0) coordinates\n",
        "x0 = grid_r_np[anchors_hw[:, 1]]\n",
        "y0 = grid_i_np[anchors_hw[:, 0]]\n",
        "anchors_xy = np.stack([x0, y0], axis=1)  # (g, 2)\n",
        "\n",
        "# 5) Compute per-channel mean/std of AJ coordinates for standardization\n",
        "#    Pack integrals into 2g channels [Re..., Im...], then compute stats over H×W.\n",
        "I_re = I_plus.real    # (g, H, W)\n",
        "I_im = I_plus.imag    # (g, H, W)\n",
        "I_ch = torch.cat([I_re, I_im], dim=0)  # (2g, H, W)\n",
        "mu = I_ch.mean(dim=(1, 2))             # (2g,)\n",
        "sigma = I_ch.std(dim=(1, 2)).clamp_min(1e-6)\n",
        "\n",
        "# Save for later use\n",
        "anchors_xy_t = torch.tensor(anchors_xy, dtype=torch.float32)\n",
        "mu_t = mu.float()\n",
        "sigma_t = sigma.float()\n",
        "\n",
        "print(\"Chosen anchors (x0,y0):\")\n",
        "for i, (x, y) in enumerate(anchors_xy):\n",
        "    print(f\"  point {i:2d}: x0={x:+.3f}, y0={y:+.3f}\")\n",
        "print(\"\\nAJ normalization ready: per-channel mean/std computed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDVFUrT-BxIR",
        "outputId": "5c4d114c-6a67-403a-df52-a37c49e4f294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen anchors (x0,y0):\n",
            "  point  0: x0=+2.084, y0=-4.232\n",
            "  point  1: x0=-0.442, y0=+5.495\n",
            "  point  2: x0=-5.242, y0=-0.947\n",
            "  point  3: x0=+4.358, y0=+1.453\n",
            "  point  4: x0=-2.463, y0=-4.611\n",
            "  point  5: x0=-3.853, y0=+2.968\n",
            "  point  6: x0=+4.611, y0=-1.958\n",
            "  point  7: x0=+2.463, y0=+4.105\n",
            "  point  8: x0=-3.600, y0=-2.589\n",
            "  point  9: x0=-0.189, y0=-4.989\n",
            "  point 10: x0=-4.989, y0=+1.200\n",
            "  point 11: x0=-2.084, y0=+3.979\n",
            "  point 12: x0=+3.979, y0=-3.853\n",
            "  point 13: x0=+1.200, y0=+5.116\n",
            "  point 14: x0=+1.200, y0=-5.242\n",
            "  point 15: x0=-4.863, y0=-2.211\n",
            "  point 16: x0=-3.474, y0=-3.853\n",
            "  point 17: x0=-4.737, y0=+0.063\n",
            "  point 18: x0=+3.095, y0=-4.737\n",
            "  point 19: x0=-1.200, y0=+4.611\n",
            "  point 20: x0=-4.232, y0=+1.958\n",
            "  point 21: x0=-3.095, y0=+3.726\n",
            "  point 22: x0=+4.105, y0=-2.842\n",
            "  point 23: x0=-1.453, y0=-4.484\n",
            "  point 24: x0=+2.968, y0=-3.726\n",
            "  point 25: x0=+1.453, y0=+4.232\n",
            "  point 26: x0=+0.316, y0=+4.863\n",
            "  point 27: x0=+0.695, y0=-4.484\n",
            "  point 28: x0=+2.211, y0=-5.116\n",
            "  point 29: x0=-4.358, y0=-0.821\n",
            "\n",
            "AJ normalization ready: per-channel mean/std computed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# 5) Data\n",
        "# ===========================\n",
        "tfm = T.Compose([T.ToTensor(), T.Normalize((0.1307,), (0.3081,))])\n",
        "train_ds = torchvision.datasets.MNIST(root=\"/content/data\", train=True, download=True, transform=tfm)\n",
        "test_ds  = torchvision.datasets.MNIST(root=\"/content/data\", train=False, download=True, transform=tfm)\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader  = torch.utils.data.DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# ===========================\n",
        "# 6) Train / Eval\n",
        "# ===========================\n",
        "def train_epoch(model, loader, opt, clip=1.0, lam_branch=1e-3, lam_bound=1e-3):\n",
        "    model.train()\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    tot, correct, n = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits, aux = model(x, return_aux=True)\n",
        "\n",
        "        loss = ce(logits, y)\n",
        "        loss = loss + lam_branch * aux[\"branch_penalty\"] + lam_bound * aux[\"bound_penalty\"]\n",
        "        loss.backward()\n",
        "        if clip is not None:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        opt.step()\n",
        "\n",
        "        tot += loss.item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        n += x.size(0)\n",
        "    return tot/n, 100.0*correct/n\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(model, loader):\n",
        "    model.eval()\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    tot, correct, n = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        tot += ce(logits, y).item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        n += x.size(0)\n",
        "    return tot/n, 100.0*correct/n"
      ],
      "metadata": {
        "id": "5AWlGtNwWoXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae5b2fd0-fb7e-42d8-b7ce-b1a493330a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 13.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 340kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.23MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Train τ-free axis-periodic AJ model with smaller batch & AMP (OOM-safe)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import defaultdict\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# -------------------- sanity: required globals --------------------\n",
        "required = [\n",
        "    \"genus\", \"I_plus\", \"Om_plus\", \"grid_r\", \"grid_i\", \"branch_pts_t\",\n",
        "    \"anchors_xy_t\", \"mu_t\", \"sigma_t\",\n",
        "    \"train_loader\", \"test_loader\",\n",
        "    \"AJMNIST_AxisPeriodic\"\n",
        "]\n",
        "for name in required:\n",
        "    if name not in globals():\n",
        "        raise RuntimeError(f\"Missing required object `{name}` before training cell.\")\n",
        "\n",
        "print(f\"Current genus = {genus}\")\n",
        "\n",
        "# -------------------- build smaller DataLoaders to save memory --------------------\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "orig_train_loader = train_loader\n",
        "orig_test_loader  = test_loader\n",
        "\n",
        "# Use a conservative batch size (e.g. 64) for AJ model\n",
        "BASE_BS = 64\n",
        "orig_bs = getattr(orig_train_loader, \"batch_size\", None)\n",
        "small_bs = BASE_BS if (orig_bs is None) else min(BASE_BS, orig_bs)\n",
        "\n",
        "train_loader_axis = DataLoader(\n",
        "    orig_train_loader.dataset,\n",
        "    batch_size=small_bs,\n",
        "    shuffle=True,\n",
        "    num_workers=getattr(orig_train_loader, \"num_workers\", 0),\n",
        "    pin_memory=getattr(orig_train_loader, \"pin_memory\", False),\n",
        "    drop_last=True\n",
        ")\n",
        "test_loader_axis = DataLoader(\n",
        "    orig_test_loader.dataset,\n",
        "    batch_size=min(256, small_bs*2),\n",
        "    shuffle=False,\n",
        "    num_workers=getattr(orig_test_loader, \"num_workers\", 0),\n",
        "    pin_memory=getattr(orig_test_loader, \"pin_memory\", False),\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "print(f\"Original train batch size: {orig_bs}\")\n",
        "print(f\"AJ-axis train batch size : {small_bs}\")\n",
        "\n",
        "# -------------------- helpers --------------------\n",
        "def count_params(m: nn.Module) -> int:\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "def heads_only_params(m: nn.Module) -> int:\n",
        "    # conv trunk is in m.base.conv\n",
        "    total = count_params(m)\n",
        "    conv_params = sum(p.numel() for p in m.base.conv.parameters() if p.requires_grad)\n",
        "    return total - conv_params\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch(model: nn.Module, loader):\n",
        "    model.eval()\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    tot, correct, n = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        tot += ce(logits, y).item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        n += x.size(0)\n",
        "    return tot/n, 100.0*correct/n\n",
        "\n",
        "# -------------------- AMP-aware training epoch --------------------\n",
        "USE_AMP = (device.type == \"cuda\")\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
        "\n",
        "def train_epoch_amp(model: nn.Module, loader, opt,\n",
        "                    clip: float = 1.0,\n",
        "                    lam_branch: float = 1e-3,\n",
        "                    lam_bound:  float = 1e-3):\n",
        "    model.train()\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    tot, correct, n = 0.0, 0, 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
        "            logits, aux = model(x, return_aux=True)\n",
        "            loss = ce(logits, y)\n",
        "            if aux is not None:\n",
        "                loss = loss + lam_branch*aux.get(\"branch_penalty\", 0.0) \\\n",
        "                             + lam_bound *aux.get(\"bound_penalty\",  0.0)\n",
        "        scaler.scale(loss).backward()\n",
        "        if clip is not None:\n",
        "            scaler.unscale_(opt)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        tot     += loss.item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        n       += x.size(0)\n",
        "    return tot/n, 100.0*correct/n\n",
        "\n",
        "# optional AJ diagnostics hook if you defined one earlier\n",
        "def maybe_aj_diags(model, loader, n_batches=2):\n",
        "    if \"aj_diags\" in globals():\n",
        "        aj_diags(model, loader, device, n_batches=n_batches)\n",
        "\n",
        "# -------------------- instantiate axis-periodic AJ model --------------------\n",
        "K = 2                 # number of Fourier harmonics per coordinate\n",
        "LEARN_FREQS = False   # fixed frequencies for τ-free head\n",
        "EMBED_DIM  = 4        # small embedding to keep params modest\n",
        "\n",
        "aj_axis = AJMNIST_AxisPeriodic(\n",
        "    genus,\n",
        "    I_plus, Om_plus,\n",
        "    grid_r, grid_i,\n",
        "    branch_pts_t,\n",
        "    anchors_xy_t.to(device),\n",
        "    mu_t.to(device), sigma_t.to(device),\n",
        "    embed_dim=EMBED_DIM,\n",
        "    K=K,\n",
        "    learnable_freqs=LEARN_FREQS\n",
        ").to(device)\n",
        "\n",
        "total_params = count_params(aj_axis)\n",
        "head_params  = heads_only_params(aj_axis)\n",
        "print(f\"\\nAJ axis-periodic (g={genus}, K={K}) params: {total_params:,}\")\n",
        "print(f\"  heads-only (total minus conv trunk): {head_params:,}\")\n",
        "\n",
        "# -------------------- optimizer (two-tier LR) --------------------\n",
        "fast_params = list(aj_axis.base.point_head.parameters()) + \\\n",
        "              [aj_axis.base.point_bias] + \\\n",
        "              list(aj_axis.torus.parameters()) + \\\n",
        "              list(aj_axis.classifier.parameters())\n",
        "\n",
        "base_params = list(aj_axis.base.conv.parameters()) + \\\n",
        "              list(aj_axis.base.aj.parameters())\n",
        "\n",
        "opt = torch.optim.AdamW(\n",
        "    [\n",
        "        {\"params\": base_params, \"lr\": 3e-4},\n",
        "        {\"params\": fast_params, \"lr\": 1e-3},\n",
        "    ],\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# -------------------- training loop --------------------\n",
        "EPOCHS     = 8\n",
        "CLIP_NORM  = 1.0\n",
        "LAM_BRANCH = 1e-3\n",
        "LAM_BOUND  = 1e-3\n",
        "\n",
        "print(\"\\nStarting training with AMP =\", USE_AMP)\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = train_epoch_amp(\n",
        "        aj_axis, train_loader_axis, opt,\n",
        "        clip=CLIP_NORM,\n",
        "        lam_branch=LAM_BRANCH,\n",
        "        lam_bound=LAM_BOUND\n",
        "    )\n",
        "    te_loss, te_acc = eval_epoch(aj_axis, test_loader_axis)\n",
        "    print(f\"[AJ axis K={K}] Epoch {ep:02d} | \"\n",
        "          f\"train {tr_loss:.4f} / {tr_acc:.2f}% | \"\n",
        "          f\"test {te_loss:.4f} / {te_acc:.2f}%\")\n",
        "    maybe_aj_diags(aj_axis, train_loader_axis, n_batches=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhY1ctYtcWuj",
        "outputId": "6a889089-7d7a-4d4e-b85e-aa4a8cbcaf99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Current genus = 30\n",
            "Original train batch size: 128\n",
            "AJ-axis train batch size : 64\n",
            "\n",
            "AJ axis-periodic (g=30, K=2) params: 22,251\n",
            "  heads-only (total minus conv trunk): 3,435\n",
            "\n",
            "Starting training with AMP = True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2695307991.py:80: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
            "/tmp/ipython-input-2695307991.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_AMP):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AJ axis K=2] Epoch 01 | train 1.9519 / 26.38% | test 1.7120 / 33.90%\n",
            "[AJ axis K=2] Epoch 02 | train 1.5955 / 39.59% | test 1.3690 / 47.23%\n",
            "[AJ axis K=2] Epoch 03 | train 1.2184 / 55.03% | test 1.0156 / 63.03%\n",
            "[AJ axis K=2] Epoch 04 | train 0.9245 / 66.91% | test 1.0187 / 62.21%\n",
            "[AJ axis K=2] Epoch 05 | train 0.7481 / 73.21% | test 0.6498 / 76.78%\n",
            "[AJ axis K=2] Epoch 06 | train 0.6925 / 75.47% | test 0.6305 / 77.39%\n",
            "[AJ axis K=2] Epoch 07 | train 0.6140 / 78.76% | test 0.5700 / 80.53%\n",
            "[AJ axis K=2] Epoch 08 | train 0.5374 / 81.91% | test 0.4593 / 84.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Parameter counts: AJ (current), Projection2D, Full 2g×2g\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# def count_params(m: nn.Module) -> int:\n",
        "#     return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "# def group_counts(m: nn.Module):\n",
        "#     from collections import defaultdict\n",
        "#     groups = defaultdict(int)\n",
        "#     for n, p in m.named_parameters():\n",
        "#         if not p.requires_grad:\n",
        "#             continue\n",
        "#         top = n.split('.')[0]  # top-level module name\n",
        "#         groups[top] += p.numel()\n",
        "#     return dict(sorted(groups.items(), key=lambda kv: kv[0]))\n",
        "\n",
        "# def pretty_mb(n_params: int, bytes_per=4):\n",
        "#     return f\"{n_params:,}  (~{n_params*bytes_per/1e6:.2f} MB @fp32)\"\n",
        "\n",
        "# def print_summary(name, m):\n",
        "#     total = count_params(m)\n",
        "#     print(f\"\\n{name}: {pretty_mb(total)}\")\n",
        "#     gc = group_counts(m)\n",
        "#     for k, v in gc.items():\n",
        "#         print(f\"  {k:15s}: {v:,}\")\n",
        "#     # heads-only (subtract conv params if present)\n",
        "#     conv_params = sum(p.numel() for n,p in m.named_parameters()\n",
        "#                       if p.requires_grad and n.startswith(\"conv\"))\n",
        "#     heads_only = total - conv_params\n",
        "#     print(f\"  {'[heads only]':15s}: {heads_only:,} (total minus conv trunk)\")\n",
        "\n",
        "# # ---------------------------\n",
        "# # Find your current AJ model\n",
        "# # ---------------------------\n",
        "# aj_candidates = [\"aj_fourier_mix\", \"aj_fourier\", \"aj_norm_model\", \"aj_period\", \"model\"]\n",
        "# aj_model = None\n",
        "# for nm in aj_candidates:\n",
        "#     if nm in globals() and isinstance(globals()[nm], nn.Module):\n",
        "#         aj_model = globals()[nm]\n",
        "#         aj_name = nm\n",
        "#         break\n",
        "\n",
        "# if aj_model is None:\n",
        "#     raise RuntimeError(\"Could not find your current AJ model instance. \"\n",
        "#                        \"Make sure you've created e.g. `aj_fourier_mix` or `aj_fourier`.\")\n",
        "\n",
        "# device = next(aj_model.parameters()).device\n",
        "# try:\n",
        "#     g = int(genus)\n",
        "# except NameError:\n",
        "#     g = 6\n",
        "\n",
        "# ---------------------------\n",
        "# Ensure Projection2D & Full2g classes exist; define fallbacks if not\n",
        "# ---------------------------\n",
        "if 'Projection2DTo2gNet' not in globals():\n",
        "    class Projection2DTo2gNet(nn.Module):\n",
        "        def __init__(self, genus):\n",
        "            super().__init__()\n",
        "            self.genus = genus\n",
        "            self.conv = nn.Sequential(\n",
        "                nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "                nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "                nn.AdaptiveAvgPool2d((1,1))\n",
        "            )\n",
        "            self.fc_down = nn.Linear(64, 2)\n",
        "            self.fc_up   = nn.Linear(2, 2*genus)\n",
        "            self.classifier = nn.Linear(2*genus, 10)\n",
        "        def forward(self, x, return_aux=False):\n",
        "            B = x.size(0)\n",
        "            h = self.conv(x).view(B, -1)\n",
        "            z2 = self.fc_down(h)\n",
        "            z  = self.fc_up(z2)\n",
        "            logits = self.classifier(z)\n",
        "            if return_aux:\n",
        "                zero = torch.zeros((), device=x.device)\n",
        "                return logits, {\"branch_penalty\": zero, \"bound_penalty\": zero}\n",
        "            return logits\n",
        "\n",
        "if 'FullMix2gNet' not in globals():\n",
        "    class FullMix2gNet(nn.Module):\n",
        "        def __init__(self, genus: int, use_nonlinearity: bool = False):\n",
        "            super().__init__()\n",
        "            self.genus = genus\n",
        "            self.use_nonlinearity = use_nonlinearity\n",
        "            self.conv = nn.Sequential(\n",
        "                nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "                nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "                nn.AdaptiveAvgPool2d((1,1))\n",
        "            )\n",
        "            self.to2g = nn.Linear(64, 2*genus)\n",
        "            self.mix2g = nn.Linear(2*genus, 2*genus)\n",
        "            self.classifier = nn.Linear(2*genus, 10)\n",
        "        def forward(self, x, return_aux=False):\n",
        "            B = x.size(0)\n",
        "            h = self.conv(x).view(B, -1)\n",
        "            z = self.to2g(h)\n",
        "            if self.use_nonlinearity:\n",
        "                z = torch.relu(z)\n",
        "            z = self.mix2g(z)\n",
        "            logits = self.classifier(z)\n",
        "            if return_aux:\n",
        "                zero = torch.zeros((), device=x.device)\n",
        "                return logits, {\"branch_penalty\": zero, \"bound_penalty\": zero}\n",
        "            return logits\n",
        "\n",
        "# # ---------------------------\n",
        "# # Build baseline model *instances* (for counting)\n",
        "# # ---------------------------\n",
        "# proj_model = Projection2DTo2gNet(g).to(device)\n",
        "# full2g_model = FullMix2gNet(g, use_nonlinearity=False).to(device)\n",
        "\n",
        "# # ---------------------------\n",
        "# # Print summaries\n",
        "# # ---------------------------\n",
        "# print_summary(f\"AJ current model [{aj_name}]\", aj_model)\n",
        "# print_summary(\"Projection2D → 2g\", proj_model)\n",
        "# print_summary(\"Full 2g×2g (linear)\", full2g_model)\n",
        "\n",
        "# # Optional: also show a 'Full 2g×2g + ReLU' variant\n",
        "# full2g_relu = FullMix2gNet(g, use_nonlinearity=True).to(device)\n",
        "# print_summary(\"Full 2g×2g (with ReLU)\", full2g_relu)\n"
      ],
      "metadata": {
        "id": "1znjRvncfix5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2D projection baseline: conv → 2 → 2g → 10 (no AJ)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ---------- sanity ----------\n",
        "if 'genus' not in globals():\n",
        "    raise RuntimeError(\"Please define `genus` first (e.g. genus = 30).\")\n",
        "if 'train_loader' not in globals() or 'test_loader' not in globals():\n",
        "    raise RuntimeError(\"Please define `train_loader` and `test_loader` first.\")\n",
        "\n",
        "print(f\"Current genus = {genus}  → 2g = {2*genus}\")\n",
        "\n",
        "# ---------- shared conv trunk (same as AJ) ----------\n",
        "def make_conv_trunk():\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        nn.AdaptiveAvgPool2d((1, 1))   # → (B,64,1,1)\n",
        "    )\n",
        "\n",
        "# optional init helper (same flavor as earlier experiments)\n",
        "def init_two_band_(tensor, low=1.0, high=3.0):\n",
        "    with torch.no_grad():\n",
        "        sign = (torch.randint(0, 2, tensor.shape, device=tensor.device)*2 - 1).float()\n",
        "        mag  = torch.empty_like(tensor, dtype=torch.float32).uniform_(low, high)\n",
        "        tensor.copy_(sign * mag)\n",
        "\n",
        "# ---------- 2D projection model ----------\n",
        "class Projection2DTo2gNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Baseline:\n",
        "      conv(1×28×28 → 64) →\n",
        "      Linear(64 → 2) →\n",
        "      Linear(2 → 2g) →\n",
        "      Linear(2g → 10)\n",
        "\n",
        "    No nonlinearity between 2 and 2g, so the representation is *strictly 2D*.\n",
        "    Increasing genus only increases parameter count, not representational dimension.\n",
        "    \"\"\"\n",
        "    def __init__(self, genus: int):\n",
        "        super().__init__()\n",
        "        self.genus = genus\n",
        "        D = 2*genus\n",
        "\n",
        "        self.conv = make_conv_trunk()\n",
        "        self.fc_down = nn.Linear(64, 2)\n",
        "        self.fc_up   = nn.Linear(2, D)\n",
        "        self.classifier = nn.Linear(D, 10)\n",
        "\n",
        "        # Match the style we used before\n",
        "        init_two_band_(self.fc_down.weight); nn.init.zeros_(self.fc_down.bias)\n",
        "        init_two_band_(self.fc_up.weight);   nn.init.zeros_(self.fc_up.bias)\n",
        "        # classifier left at default init for parity with AJ code\n",
        "\n",
        "    def forward(self, x, return_aux=False):\n",
        "        B = x.size(0)\n",
        "        h = self.conv(x).view(B, -1)     # (B, 64)\n",
        "        z2  = self.fc_down(h)            # (B, 2)\n",
        "        z2g = self.fc_up(z2)             # (B, 2g)\n",
        "        logits = self.classifier(z2g)    # (B, 10)\n",
        "\n",
        "        if return_aux:\n",
        "            # Dummy aux so we can reuse AJ-style training loops if desired\n",
        "            zero = torch.zeros((), device=x.device)\n",
        "            aux = {\"branch_penalty\": zero, \"bound_penalty\": zero}\n",
        "            return logits, aux\n",
        "        return logits\n",
        "\n",
        "# ---------- training helpers ----------\n",
        "def count_params(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch_plain(model, loader):\n",
        "    model.eval()\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    tot, correct, n = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = ce(logits, y)\n",
        "        tot     += loss.item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        n += x.size(0)\n",
        "    return tot/n, 100.0*correct/n\n",
        "\n",
        "def train_epoch_plain(model, loader, opt, clip=None):\n",
        "    model.train()\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    tot, correct, n = 0.0, 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        logits = model(x)\n",
        "        loss = ce(logits, y)\n",
        "        loss.backward()\n",
        "        if clip is not None:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "        opt.step()\n",
        "        tot     += loss.item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        n       += x.size(0)\n",
        "    return tot/n, 100.0*correct/n\n",
        "\n",
        "# ---------- instantiate & train ----------\n",
        "proj2d = Projection2DTo2gNet(genus).to(device)\n",
        "opt_proj = torch.optim.AdamW(proj2d.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "total_params = count_params(proj2d)\n",
        "print(f\"\\nProjection2DTo2gNet params (g={genus}): {total_params:,}\")\n",
        "\n",
        "EPOCHS = 8\n",
        "CLIP   = 1.0\n",
        "\n",
        "print(\"\\nStarting training of 2D projection baseline...\")\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = train_epoch_plain(proj2d, train_loader, opt_proj, clip=CLIP)\n",
        "    te_loss, te_acc = eval_epoch_plain(proj2d, test_loader)\n",
        "    print(f\"[PROJ-2D→2g g={genus}] Ep {ep:02d} | \"\n",
        "          f\"train {tr_loss:.4f} / {tr_acc:.2f}% | \"\n",
        "          f\"test {te_loss:.4f} / {te_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGCMLGTdkePJ",
        "outputId": "cfa68d12-2438-42c7-8cab-3d66e7c40e60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Current genus = 30  → 2g = 60\n",
            "\n",
            "Projection2DTo2gNet params (g=30): 19,736\n",
            "\n",
            "Starting training of 2D projection baseline...\n",
            "[PROJ-2D→2g g=30] Ep 01 | train 1.4776 / 42.54% | test 1.1763 / 53.17%\n",
            "[PROJ-2D→2g g=30] Ep 02 | train 1.0915 / 56.52% | test 0.9643 / 63.14%\n",
            "[PROJ-2D→2g g=30] Ep 03 | train 0.9546 / 63.07% | test 0.8682 / 67.89%\n",
            "[PROJ-2D→2g g=30] Ep 04 | train 0.8876 / 66.87% | test 1.0759 / 58.88%\n",
            "[PROJ-2D→2g g=30] Ep 05 | train 0.8346 / 69.56% | test 0.7492 / 73.22%\n",
            "[PROJ-2D→2g g=30] Ep 06 | train 0.7526 / 73.13% | test 0.7266 / 73.31%\n",
            "[PROJ-2D→2g g=30] Ep 07 | train 0.6960 / 75.66% | test 0.6455 / 78.14%\n",
            "[PROJ-2D→2g g=30] Ep 08 | train 0.6683 / 76.83% | test 0.5790 / 81.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UpsXiFuvgzKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(genus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9E0Z8__g0BH",
        "outputId": "cfd6ad41-cd90-4653-93f6-342b4f274c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Compact τ-free axis-periodic AJ model (definition + training)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, os, time\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# --------- sanity checks for precomputed objects ---------\n",
        "needed = [\n",
        "    \"genus\", \"I_plus\", \"Om_plus\", \"grid_r\", \"grid_i\", \"branch_pts_t\",\n",
        "    \"anchors_xy_t\", \"mu_t\", \"sigma_t\", \"AJMNIST_Anchored\", \"TorusFeatures\",\n",
        "    \"train_loader\", \"test_loader\"\n",
        "]\n",
        "for name in needed:\n",
        "    if name not in globals():\n",
        "        raise RuntimeError(f\"Missing `{name}`; make sure your genus-{globals().get('genus','?')} setup cells ran.\")\n",
        "\n",
        "print(f\"Current genus = {genus}\")\n",
        "\n",
        "# If you already have smaller-batch loaders from the previous cell, reuse them:\n",
        "train_loader_compact = train_loader_axis if 'train_loader_axis' in globals() else train_loader\n",
        "test_loader_compact  = test_loader_axis  if 'test_loader_axis'  in globals() else test_loader\n",
        "print(\"train_loader_compact batch_size:\", train_loader_compact.batch_size)\n",
        "\n",
        "# --------- helper: fixed orthogonal projector ---------\n",
        "def make_fixed_orthogonal(D: int, r: int, seed: int = 1234):\n",
        "    \"\"\"\n",
        "    Returns a D x r matrix with orthonormal columns (Q), as float32.\n",
        "    Used as a non-trainable bottleneck from feature dim D to r.\n",
        "    \"\"\"\n",
        "    assert r <= D, f\"r={r} must be ≤ D={D}\"\n",
        "    gen = torch.Generator().manual_seed(seed)\n",
        "    A = torch.randn(D, r, generator=gen)\n",
        "    Q, _ = torch.linalg.qr(A, mode='reduced')  # D x r\n",
        "    return Q[:, :r].float()\n",
        "\n",
        "# --------- compact axis-periodic model ---------\n",
        "class AJMNIST_AxisPeriodic_Compact(nn.Module):\n",
        "    \"\"\"\n",
        "    AJ base (anchored + normalized) + axis-aligned Fourier torus features,\n",
        "    followed by a FIXED orthogonal projector P: R^{D_feat} → R^r and a tiny classifier.\n",
        "\n",
        "    D_feat = 2*(2g)*K (cos/sin per coordinate per harmonic)\n",
        "    \"\"\"\n",
        "    def __init__(self, genus, I_plus, Om_plus, grid_r, grid_i, branch_pts,\n",
        "                 anchors_xy, mu, sigma,\n",
        "                 embed_dim=8, K=2, r=32,\n",
        "                 learnable_freqs=False, proj_seed=1234):\n",
        "        super().__init__()\n",
        "        self.base = AJMNIST_Anchored(\n",
        "            genus, I_plus, Om_plus,\n",
        "            grid_r, grid_i, branch_pts,\n",
        "            anchors_xy, mu, sigma,\n",
        "            embed_dim=embed_dim\n",
        "        )\n",
        "        self.K = K\n",
        "        D = 2*genus\n",
        "        self.torus = TorusFeatures(D, K=K, learnable=learnable_freqs)\n",
        "        D_feat = 2 * D * K   # cos+sin per dim per harmonic\n",
        "        assert r <= D_feat, f\"r={r} must be ≤ D_feat={D_feat} for K={K}, g={genus}\"\n",
        "        P = make_fixed_orthogonal(D_feat, r, seed=proj_seed)\n",
        "        self.register_buffer(\"P\", P)               # non-trainable projector\n",
        "        self.scale = nn.Parameter(torch.ones(r))   # tiny learned diagonal scale\n",
        "        self.classifier = nn.Linear(r, 10)         # small head\n",
        "\n",
        "    @property\n",
        "    def genus(self):\n",
        "        return self.base.genus\n",
        "\n",
        "    def forward(self, x, return_aux=False):\n",
        "        B = x.size(0)\n",
        "        # shared conv + point head (same as axis model)\n",
        "        h = self.base.conv(x).view(B, -1)\n",
        "        h_exp = h.unsqueeze(1).expand(-1, self.genus, -1)\n",
        "        emb   = self.base.embed.unsqueeze(0).expand(B, -1, -1)\n",
        "        out   = self.base.point_head(torch.cat([h_exp, emb], dim=2)) \\\n",
        "              + self.base.point_bias.unsqueeze(0)\n",
        "        raw_xy, sheet_logits = out[..., :2], out[..., 2]\n",
        "\n",
        "        coords_std, aux = self.base.aj(raw_xy, sheet_logits, return_aux=True)  # (B, 2g)\n",
        "        feats = self.torus(coords_std)                                         # (B, D_feat)\n",
        "        P = self.P.to(feats.device, dtype=feats.dtype)                         # (D_feat, r)\n",
        "        z = feats @ P                                                          # (B, r)\n",
        "        z = z * self.scale                                                     # (B, r)\n",
        "        logits = self.classifier(z)                                            # (B, 10)\n",
        "        if return_aux:\n",
        "            return logits, aux\n",
        "        return logits\n",
        "\n",
        "# --------- param counting helpers ---------\n",
        "def count_params(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "def heads_only_params(m):\n",
        "    total = count_params(m)\n",
        "    conv_params = sum(p.numel() for p in m.base.conv.parameters() if p.requires_grad)\n",
        "    return total - conv_params\n",
        "\n",
        "# --------- AMP-aware training helpers (reuse if present) ---------\n",
        "if 'train_epoch_amp' not in globals():\n",
        "    print(\"Defining train_epoch_amp locally (AMP training).\")\n",
        "    ce = nn.CrossEntropyLoss()\n",
        "    USE_AMP = (device.type == 'cuda')\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
        "\n",
        "    def train_epoch_amp(model, loader, opt,\n",
        "                        clip=1.0, lam_branch=1e-3, lam_bound=1e-3):\n",
        "        model.train()\n",
        "        tot, correct, n = 0.0, 0, 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
        "                logits, aux = model(x, return_aux=True)\n",
        "                loss = ce(logits, y)\n",
        "                loss = loss + lam_branch*aux.get(\"branch_penalty\", 0.0) \\\n",
        "                           + lam_bound *aux.get(\"bound_penalty\",  0.0)\n",
        "            scaler.scale(loss).backward()\n",
        "            if clip is not None:\n",
        "                scaler.unscale_(opt)\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            tot     += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            n       += x.size(0)\n",
        "        return tot/n, 100.0*correct/n\n",
        "\n",
        "if 'eval_epoch' not in globals():\n",
        "    ce_eval = nn.CrossEntropyLoss()\n",
        "    @torch.no_grad()\n",
        "    def eval_epoch(model, loader):\n",
        "        model.eval()\n",
        "        tot, correct, n = 0.0, 0, 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = ce_eval(logits, y)\n",
        "            tot     += loss.item() * x.size(0)\n",
        "            correct += (logits.argmax(1) == y).sum().item()\n",
        "            n += x.size(0)\n",
        "        return tot/n, 100.0*correct/n\n",
        "\n",
        "# Optional AJ diagnostics\n",
        "def maybe_aj_diags(model, loader, n_batches=2):\n",
        "    if \"aj_diags\" in globals():\n",
        "        aj_diags(model, loader, device, n_batches=n_batches)\n",
        "\n",
        "# --------- move lookup tables to device if needed ---------\n",
        "# If you already have device copies, reuse; else create them.\n",
        "I_plus_dev  = I_plus.to(device)   if I_plus.device.type  == 'cpu' else I_plus\n",
        "Om_plus_dev = Om_plus.to(device)  if Om_plus.device.type == 'cpu' else Om_plus\n",
        "grid_r_dev  = grid_r.to(device)\n",
        "grid_i_dev  = grid_i.to(device)\n",
        "branch_pts_dev = branch_pts_t.to(device)\n",
        "anchors_xy_dev = anchors_xy_t.to(device)\n",
        "mu_dev, sigma_dev = mu_t.to(device), sigma_t.to(device)\n",
        "\n",
        "# --------- instantiate compact model ---------\n",
        "K = 2       # harmonics per coordinate (same as axis model)\n",
        "r = 32      # compact dimension (you can tune this)\n",
        "EMBED_DIM = 4\n",
        "\n",
        "aj_axis_compact = AJMNIST_AxisPeriodic_Compact(\n",
        "    genus,\n",
        "    I_plus_dev, Om_plus_dev,\n",
        "    grid_r_dev, grid_i_dev,\n",
        "    branch_pts_dev,\n",
        "    anchors_xy_dev,\n",
        "    mu_dev, sigma_dev,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    K=K, r=r,\n",
        "    learnable_freqs=False,\n",
        "    proj_seed=1234\n",
        ").to(device)\n",
        "\n",
        "total = count_params(aj_axis_compact)\n",
        "heads = heads_only_params(aj_axis_compact)\n",
        "conv  = sum(p.numel() for p in aj_axis_compact.base.conv.parameters() if p.requires_grad)\n",
        "print(f\"\\nAJ axis-periodic COMPACT (g={genus}, K={K}, r={r})\")\n",
        "print(f\"  total params  : {total:,}\")\n",
        "print(f\"  conv trunk    : {conv:,}\")\n",
        "print(f\"  heads-only    : {heads:,} (total minus conv trunk)\")\n",
        "\n",
        "# --------- optimizer (two-tier) ---------\n",
        "fast_params = list(aj_axis_compact.base.point_head.parameters()) + \\\n",
        "              [aj_axis_compact.base.point_bias] + \\\n",
        "              list(aj_axis_compact.torus.parameters()) + \\\n",
        "              list(aj_axis_compact.classifier.parameters())\n",
        "\n",
        "base_params = list(aj_axis_compact.base.conv.parameters()) + \\\n",
        "              list(aj_axis_compact.base.aj.parameters())\n",
        "\n",
        "opt_compact = torch.optim.AdamW(\n",
        "    [\n",
        "        {\"params\": base_params, \"lr\": 3e-4},\n",
        "        {\"params\": fast_params, \"lr\": 1e-3},\n",
        "    ],\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "# --------- train compact model ---------\n",
        "EPOCHS     = 8\n",
        "CLIP_NORM  = 1.0\n",
        "LAM_BRANCH = 1e-3\n",
        "LAM_BOUND  = 1e-3\n",
        "\n",
        "USE_AMP = (device.type == 'cuda')\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
        "\n",
        "print(\"\\nStarting training of COMPACT axis-periodic model (AMP =\", USE_AMP, \")\")\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = train_epoch_amp(\n",
        "        aj_axis_compact, train_loader_compact, opt_compact,\n",
        "        clip=CLIP_NORM, lam_branch=LAM_BRANCH, lam_bound=LAM_BOUND\n",
        "    )\n",
        "    te_loss, te_acc = eval_epoch(aj_axis_compact, test_loader_compact)\n",
        "    print(f\"[AJ axis COMPACT K={K}, r={r}] Ep {ep:02d} | \"\n",
        "          f\"train {tr_loss:.4f} / {tr_acc:.2f}% | \"\n",
        "          f\"test {te_loss:.4f} / {te_acc:.2f}%\")\n",
        "    maybe_aj_diags(aj_axis_compact, train_loader_compact, n_batches=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoLajolRctHh",
        "outputId": "0ff33233-5324-4810-bb6f-d46efd06113f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Current genus = 30\n",
            "train_loader_compact batch_size: 64\n",
            "\n",
            "AJ axis-periodic COMPACT (g=30, K=2, r=32)\n",
            "  total params  : 20,203\n",
            "  conv trunk    : 18,816\n",
            "  heads-only    : 1,387 (total minus conv trunk)\n",
            "\n",
            "Starting training of COMPACT axis-periodic model (AMP = True )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2697331024.py:212: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
            "/tmp/ipython-input-2695307991.py:93: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_AMP):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AJ axis COMPACT K=2, r=32] Ep 01 | train 2.0593 / 23.81% | test 1.7942 / 32.60%\n",
            "[AJ axis COMPACT K=2, r=32] Ep 02 | train 1.4766 / 44.19% | test 1.1779 / 55.43%\n",
            "[AJ axis COMPACT K=2, r=32] Ep 03 | train 1.1128 / 59.24% | test 0.9999 / 63.87%\n",
            "[AJ axis COMPACT K=2, r=32] Ep 04 | train 0.8361 / 72.98% | test 0.6871 / 79.65%\n",
            "[AJ axis COMPACT K=2, r=32] Ep 05 | train 0.6344 / 81.71% | test 0.5646 / 85.02%\n",
            "[AJ axis COMPACT K=2, r=32] Ep 06 | train 0.5767 / 83.33% | test 0.4633 / 87.36%\n",
            "[AJ axis COMPACT K=2, r=32] Ep 07 | train 0.4887 / 86.04% | test 0.3753 / 90.00%\n",
            "[AJ axis COMPACT K=2, r=32] Ep 08 | train 0.4015 / 88.65% | test 0.3505 / 90.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Full 2g×2g baseline: conv → 2g → 2g → 10 (no AJ)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ---------- sanity ----------\n",
        "if \"genus\" not in globals():\n",
        "    raise RuntimeError(\"`genus` is not defined; run your setup cell first (e.g., genus = 30).\")\n",
        "if \"train_loader\" not in globals() or \"test_loader\" not in globals():\n",
        "    raise RuntimeError(\"`train_loader` / `test_loader` missing; make sure your dataset loaders exist.\")\n",
        "\n",
        "print(f\"Full 2g×2g baseline will use genus = {genus}\")\n",
        "D2g = 2 * genus\n",
        "\n",
        "# ---------- shared conv trunk (same as AJ models) ----------\n",
        "def make_conv_trunk():\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        nn.AdaptiveAvgPool2d((1, 1))\n",
        "    )\n",
        "\n",
        "# ---------- full 2g×2g model ----------\n",
        "class Full2gMixerNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Baseline:\n",
        "      conv(1×28×28 → 64) →\n",
        "      Linear(64 → 2g) →\n",
        "      [optional ReLU] →\n",
        "      Linear(2g → 2g) →\n",
        "      Linear(2g → 10)\n",
        "\n",
        "    No AJ, no torus. This is the \"big\" baseline that directly mixes a 2g-dimensional\n",
        "    feature space with a full 2g×2g weight matrix.\n",
        "    \"\"\"\n",
        "    def __init__(self, genus: int, use_relu: bool = False):\n",
        "        super().__init__()\n",
        "        self.genus = genus\n",
        "        self.use_relu = use_relu\n",
        "        D = 2 * genus\n",
        "\n",
        "        self.conv = make_conv_trunk()\n",
        "        self.to2g   = nn.Linear(64, D)\n",
        "        self.mix2g  = nn.Linear(D, D)\n",
        "        self.classifier = nn.Linear(D, 10)\n",
        "\n",
        "        # Optional: Kaiming inits for the 2g layers\n",
        "        nn.init.kaiming_uniform_(self.to2g.weight, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.to2g.bias)\n",
        "        nn.init.kaiming_uniform_(self.mix2g.weight, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.mix2g.bias)\n",
        "        # classifier left at default init\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.size(0)\n",
        "        h = self.conv(x).view(B, -1)   # (B, 64)\n",
        "\n",
        "        z = self.to2g(h)               # (B, 2g)\n",
        "        if self.use_relu:\n",
        "            z = F.relu(z)\n",
        "        z = self.mix2g(z)              # (B, 2g)\n",
        "        logits = self.classifier(z)    # (B, 10)\n",
        "        return logits\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def count_params(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "def conv_params(m):\n",
        "    return sum(p.numel() for n,p in m.named_parameters()\n",
        "               if p.requires_grad and n.startswith(\"conv\"))\n",
        "\n",
        "def heads_only_params(m):\n",
        "    return count_params(m) - conv_params(m)\n",
        "\n",
        "if \"train_epoch_plain\" not in globals():\n",
        "    def train_epoch_plain(model, loader, opt, clip=None):\n",
        "        model.train()\n",
        "        ce = nn.CrossEntropyLoss()\n",
        "        tot_loss, correct, n = 0.0, 0, 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(x)\n",
        "            loss = ce(logits, y)\n",
        "            loss.backward()\n",
        "            if clip is not None:\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            opt.step()\n",
        "            tot_loss += loss.item() * x.size(0)\n",
        "            correct  += (logits.argmax(1) == y).sum().item()\n",
        "            n += x.size(0)\n",
        "        return tot_loss/n, 100.0*correct/n\n",
        "\n",
        "if \"eval_epoch_plain\" not in globals():\n",
        "    @torch.no_grad()\n",
        "    def eval_epoch_plain(model, loader):\n",
        "        model.eval()\n",
        "        ce = nn.CrossEntropyLoss()\n",
        "        tot_loss, correct, n = 0.0, 0, 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = ce(logits, y)\n",
        "            tot_loss += loss.item() * x.size(0)\n",
        "            correct  += (logits.argmax(1) == y).sum().item()\n",
        "            n += x.size(0)\n",
        "        return tot_loss/n, 100.0*correct/n\n",
        "\n",
        "# ---------- instantiate & train (linear version by default) ----------\n",
        "use_relu = False   # set True if you also want the ReLU variant\n",
        "\n",
        "full2g = Full2gMixerNet(genus, use_relu=use_relu).to(device)\n",
        "opt_full2g = torch.optim.AdamW(full2g.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "total = count_params(full2g)\n",
        "conv  = conv_params(full2g)\n",
        "heads = heads_only_params(full2g)\n",
        "print(f\"\\nFull2gMixerNet (g={genus}, use_relu={use_relu}) params: {total:,}\")\n",
        "print(f\"  conv trunk : {conv:,}\")\n",
        "print(f\"  heads-only : {heads:,} (total minus conv trunk)\")\n",
        "\n",
        "EPOCHS = 8\n",
        "CLIP   = 1.0\n",
        "\n",
        "print(\"\\nStarting training of full 2g×2g baseline...\")\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = train_epoch_plain(full2g, train_loader, opt_full2g, clip=CLIP)\n",
        "    te_loss, te_acc = eval_epoch_plain(full2g, test_loader)\n",
        "    print(f\"[FULL 2g×2g g={genus}, relu={use_relu}] Ep {ep:02d} | \"\n",
        "          f\"train {tr_loss:.4f} / {tr_acc:.2f}% | \"\n",
        "          f\"test {te_loss:.4f} / {te_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWwBiou7ctdN",
        "outputId": "18320765-d0bc-4291-b5d3-2d50f82ae389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Full 2g×2g baseline will use genus = 30\n",
            "\n",
            "Full2gMixerNet (g=30, use_relu=False) params: 26,986\n",
            "  conv trunk : 18,816\n",
            "  heads-only : 8,170 (total minus conv trunk)\n",
            "\n",
            "Starting training of full 2g×2g baseline...\n",
            "[FULL 2g×2g g=30, relu=False] Ep 01 | train 1.6765 / 37.43% | test 1.2858 / 52.60%\n",
            "[FULL 2g×2g g=30, relu=False] Ep 02 | train 1.1381 / 58.55% | test 0.9864 / 64.70%\n",
            "[FULL 2g×2g g=30, relu=False] Ep 03 | train 0.9854 / 64.65% | test 0.8870 / 69.01%\n",
            "[FULL 2g×2g g=30, relu=False] Ep 04 | train 0.9055 / 68.36% | test 0.8473 / 70.84%\n",
            "[FULL 2g×2g g=30, relu=False] Ep 05 | train 0.8243 / 72.16% | test 0.7878 / 72.90%\n",
            "[FULL 2g×2g g=30, relu=False] Ep 06 | train 0.7275 / 76.57% | test 0.6396 / 78.74%\n",
            "[FULL 2g×2g g=30, relu=False] Ep 07 | train 0.6213 / 81.04% | test 0.5240 / 84.50%\n",
            "[FULL 2g×2g g=30, relu=False] Ep 08 | train 0.5103 / 84.85% | test 0.4292 / 87.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# @title Full 2g×2g baseline: conv → 2g → 2g → 10 (no AJ):  now turn on relu\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ---------- sanity ----------\n",
        "if \"genus\" not in globals():\n",
        "    raise RuntimeError(\"`genus` is not defined; run your setup cell first (e.g., genus = 30).\")\n",
        "if \"train_loader\" not in globals() or \"test_loader\" not in globals():\n",
        "    raise RuntimeError(\"`train_loader` / `test_loader` missing; make sure your dataset loaders exist.\")\n",
        "\n",
        "print(f\"Full 2g×2g baseline will use genus = {genus}\")\n",
        "D2g = 2 * genus\n",
        "\n",
        "# ---------- shared conv trunk (same as AJ models) ----------\n",
        "def make_conv_trunk():\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        nn.AdaptiveAvgPool2d((1, 1))\n",
        "    )\n",
        "\n",
        "# ---------- full 2g×2g model ----------\n",
        "class Full2gMixerNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Baseline:\n",
        "      conv(1×28×28 → 64) →\n",
        "      Linear(64 → 2g) →\n",
        "      [optional ReLU] →\n",
        "      Linear(2g → 2g) →\n",
        "      Linear(2g → 10)\n",
        "\n",
        "    No AJ, no torus. This is the \"big\" baseline that directly mixes a 2g-dimensional\n",
        "    feature space with a full 2g×2g weight matrix.\n",
        "    \"\"\"\n",
        "    def __init__(self, genus: int, use_relu: bool = False):\n",
        "        super().__init__()\n",
        "        self.genus = genus\n",
        "        self.use_relu = use_relu\n",
        "        D = 2 * genus\n",
        "\n",
        "        self.conv = make_conv_trunk()\n",
        "        self.to2g   = nn.Linear(64, D)\n",
        "        self.mix2g  = nn.Linear(D, D)\n",
        "        self.classifier = nn.Linear(D, 10)\n",
        "\n",
        "        # Optional: Kaiming inits for the 2g layers\n",
        "        nn.init.kaiming_uniform_(self.to2g.weight, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.to2g.bias)\n",
        "        nn.init.kaiming_uniform_(self.mix2g.weight, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.mix2g.bias)\n",
        "        # classifier left at default init\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.size(0)\n",
        "        h = self.conv(x).view(B, -1)   # (B, 64)\n",
        "\n",
        "        z = self.to2g(h)               # (B, 2g)\n",
        "        if self.use_relu:\n",
        "            z = F.relu(z)\n",
        "        z = self.mix2g(z)              # (B, 2g)\n",
        "        logits = self.classifier(z)    # (B, 10)\n",
        "        return logits\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def count_params(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "def conv_params(m):\n",
        "    return sum(p.numel() for n,p in m.named_parameters()\n",
        "               if p.requires_grad and n.startswith(\"conv\"))\n",
        "\n",
        "def heads_only_params(m):\n",
        "    return count_params(m) - conv_params(m)\n",
        "\n",
        "if \"train_epoch_plain\" not in globals():\n",
        "    def train_epoch_plain(model, loader, opt, clip=None):\n",
        "        model.train()\n",
        "        ce = nn.CrossEntropyLoss()\n",
        "        tot_loss, correct, n = 0.0, 0, 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(x)\n",
        "            loss = ce(logits, y)\n",
        "            loss.backward()\n",
        "            if clip is not None:\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            opt.step()\n",
        "            tot_loss += loss.item() * x.size(0)\n",
        "            correct  += (logits.argmax(1) == y).sum().item()\n",
        "            n += x.size(0)\n",
        "        return tot_loss/n, 100.0*correct/n\n",
        "\n",
        "if \"eval_epoch_plain\" not in globals():\n",
        "    @torch.no_grad()\n",
        "    def eval_epoch_plain(model, loader):\n",
        "        model.eval()\n",
        "        ce = nn.CrossEntropyLoss()\n",
        "        tot_loss, correct, n = 0.0, 0, 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = ce(logits, y)\n",
        "            tot_loss += loss.item() * x.size(0)\n",
        "            correct  += (logits.argmax(1) == y).sum().item()\n",
        "            n += x.size(0)\n",
        "        return tot_loss/n, 100.0*correct/n\n",
        "\n",
        "# ---------- instantiate & train (linear version by default) ----------\n",
        "use_relu = True   # set True if you also want the ReLU variant\n",
        "\n",
        "full2g = Full2gMixerNet(genus, use_relu=use_relu).to(device)\n",
        "opt_full2g = torch.optim.AdamW(full2g.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "total = count_params(full2g)\n",
        "conv  = conv_params(full2g)\n",
        "heads = heads_only_params(full2g)\n",
        "print(f\"\\nFull2gMixerNet (g={genus}, use_relu={use_relu}) params: {total:,}\")\n",
        "print(f\"  conv trunk : {conv:,}\")\n",
        "print(f\"  heads-only : {heads:,} (total minus conv trunk)\")\n",
        "\n",
        "EPOCHS = 8\n",
        "CLIP   = 1.0\n",
        "\n",
        "print(\"\\nStarting training of full 2g×2g baseline...\")\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_acc = train_epoch_plain(full2g, train_loader, opt_full2g, clip=CLIP)\n",
        "    te_loss, te_acc = eval_epoch_plain(full2g, test_loader)\n",
        "    print(f\"[FULL 2g×2g g={genus}, relu={use_relu}] Ep {ep:02d} | \"\n",
        "          f\"train {tr_loss:.4f} / {tr_acc:.2f}% | \"\n",
        "          f\"test {te_loss:.4f} / {te_acc:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnRuOmuWkT81",
        "outputId": "b3b34e7c-6cf0-4b28-a403-c38df824e40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Full 2g×2g baseline will use genus = 30\n",
            "\n",
            "Full2gMixerNet (g=30, use_relu=True) params: 26,986\n",
            "  conv trunk : 18,816\n",
            "  heads-only : 8,170 (total minus conv trunk)\n",
            "\n",
            "Starting training of full 2g×2g baseline...\n",
            "[FULL 2g×2g g=30, relu=True] Ep 01 | train 1.7115 / 35.73% | test 1.2891 / 50.89%\n",
            "[FULL 2g×2g g=30, relu=True] Ep 02 | train 1.2209 / 54.13% | test 1.0996 / 59.92%\n",
            "[FULL 2g×2g g=30, relu=True] Ep 03 | train 1.0737 / 61.08% | test 0.9570 / 66.27%\n",
            "[FULL 2g×2g g=30, relu=True] Ep 04 | train 0.9104 / 69.00% | test 0.7928 / 73.39%\n",
            "[FULL 2g×2g g=30, relu=True] Ep 05 | train 0.7682 / 74.64% | test 0.6654 / 78.48%\n",
            "[FULL 2g×2g g=30, relu=True] Ep 06 | train 0.6521 / 78.90% | test 0.5723 / 81.22%\n",
            "[FULL 2g×2g g=30, relu=True] Ep 07 | train 0.5691 / 81.76% | test 0.5146 / 83.17%\n",
            "[FULL 2g×2g g=30, relu=True] Ep 08 | train 0.5064 / 84.00% | test 0.4534 / 85.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-qr2CuKqkT5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sCu9KgRekT1O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}